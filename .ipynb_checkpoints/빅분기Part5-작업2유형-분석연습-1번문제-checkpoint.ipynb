{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "729ac4cf",
   "metadata": {},
   "source": [
    "# 빅분기Part5-작업2유형-분석연습-1번문제\n",
    "p.389~ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f72dc83",
   "metadata": {},
   "source": [
    "### 문제1\n",
    "고객 3500명에 대한 학습용 데이터(x_train, y_train)을 이용하여 성별 예측 모형을 만든 후, 이를 평가용 데이터(x_test)에 적용하여 얻은 2482명 고객의 성별 예측값(남자일 확률)을 다음과 같은 형식의 csv 파일로 생성하시오 (제출한 모델의 성능은 ROC-AUC 평가지표에 따라 채점)\n",
    "- y_train: 고객의 성별 데이터. 학습 데이터. 3500명\n",
    "- x_train, x_test: 고객의 상품 구매 속성. 학습 및 평가용\n",
    "\n",
    "##### 제출 형식\n",
    "- custid, gender\n",
    "- 3500, 0.267\n",
    "- 3501, 0.578\n",
    "- 3502, 0.885"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4228995",
   "metadata": {},
   "source": [
    "- 22.6.19.일 22:22 데이터 로드만.\n",
    "- 22.6.20.월 14:30~16:57 predict 에서 Memory부족 에러나고 막힘. 8GB 넘게 먹어서 이 놋북에서 실행불가. 혹은 램 덜 먹게 조치??\n",
    "> n_estimators= 10 으로 해결\n",
    "- 22.6.20.월 18:00~22:30 ValueError: could not broadcast input array from shape (3500,3500) into shape (3500,) 및 #ValueError: multiclass-multioutput format is not supported\n",
    "> y_test_proba 의 형태가 (2,3500,3500) 꼴로 나온다. 왜지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44e9fcf",
   "metadata": {},
   "source": [
    "y_train에 index가 포함된 경우\n",
    "#### predict 는 슬라이싱 하지 말아야 하고\n",
    "- model.fit(x_train, y_train) #display(pd.DataFrame(y_train_predict).head()) # <<< 2열 (인덱스,예측 결과값)\n",
    "- y_test_predict= model.predict(x_test) \n",
    "\n",
    "#### proba 는 슬라이싱 해서 gender 만 내도록 해야 한다.\n",
    "- model.fit(x_train, y_train.iloc[:,1]) # <<< 없는 cust_id 가 방해가 되나 싶어서 1열만 내도록 학습\n",
    "- y_test_proba= model.predict_proba(x_test) # <<< train 으로 만든 모델에 x_test 넣기. 결과 제출용으로 필수\n",
    "\n",
    "#### 애초에 y_train 에서 index 부분은 drop 하고 따로 저장했어야?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e42502",
   "metadata": {},
   "source": [
    "##### error 회피하려다 초가삼간 태운다\n",
    "그렇게 추정한 각 정보는 누구 id 것인데?\n",
    "> id 붙이면 해결!. train 으로 model 만들적부터 오름차순으로만 되어있으면 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3c1662",
   "metadata": {},
   "source": [
    "### 주석 싹싹 지우고 다시2\n",
    "22.6.21 15:44/ y_train 에서 id 빼고 학습시켜야 한다. concat 은 Series 끼리만 []로 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3891768e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델링전까지 수행시간: 0.201998 sec\n",
      "모델링 시간: 0.112001 sec\n",
      "전체 수행 시간: 0.313999 sec\n"
     ]
    }
   ],
   "source": [
    "## 데이터 로드, null, dtypes 체크 #이상치 체크, 인코딩, 파생변수, 상관관계, 변수 드랍, x_test에도 전처리 \n",
    "## 스케일링 # 모델링, train score, test score # id붙이기, to_csv\n",
    "\n",
    "## gender 일 확률. proba\n",
    "import time\n",
    "start_time= time.time()\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',None)\n",
    "x_train= pd.read_csv('bigData/x_train.csv', encoding='CP949')\n",
    "y_train= pd.read_csv('bigData/y_train.csv', encoding='CP949')\n",
    "x_test= pd.read_csv('bigData/x_test.csv', encoding='CP949') # Wow! x_test 넣어야할 것을 x_train 넣었었다.\n",
    "\n",
    "## null 처리. 환불 null 은 환불이 없었다고 가정. fillna(0)\n",
    "x_train['환불금액']= x_train['환불금액'].fillna(0)\n",
    "x_test['환불금액']= x_test['환불금액'].fillna(0)\n",
    "\n",
    "## dtypes 체크 - 숫자인데 문자로 되어있는 건 아니 보인다\n",
    "\n",
    "## 이상치 보기. 구매액이 매우 크다고 해서 절삭하는 건 말이 안 된다고 본다.\n",
    "def outlierCheck(data):\n",
    "    dataNum= data.loc[:,data.dtypes!=object] # 숫자만\n",
    "    desc= dataNum.describe()\n",
    "    min1= desc.loc['min']\n",
    "    max1= desc.loc['max']\n",
    "    std= desc.loc['std']\n",
    "    mean= desc.loc['mean']\n",
    "    maxBoundary= mean+1.5*std\n",
    "    minBoundary= mean-1.5*std\n",
    "    \n",
    "    return minBoundary, maxBoundary\n",
    "\n",
    "minB, maxB= outlierCheck(x_train)\n",
    "minB_test, maxB_test= outlierCheck(x_test)\n",
    "\n",
    "## 파생변수. 주말방문 경험 유무? 1회 최대구매액 구간- boundary 밖 & median? 환불여부?\n",
    "conditionWeekend= x_train['주말방문비율']>0\n",
    "x_train.loc[conditionWeekend, '주말방문여부']= 1\n",
    "x_train.loc[~conditionWeekend, '주말방문여부']= 0\n",
    "\n",
    "conditionRefund= x_train['환불금액']>0\n",
    "x_train.loc[conditionRefund, '환불여부']= 1\n",
    "x_train.loc[~conditionRefund, '환불여부']= 0\n",
    "\n",
    "conditionMaxBuyOutlier= x_train['최대구매액']> maxB['최대구매액']\n",
    "conditionMaxBuy= (x_train['최대구매액']<= maxB['최대구매액']) & (x_train['최대구매액'] > x_train['최대구매액'].median())\n",
    "conditionMaxBuySmall= x_train['최대구매액'] <= x_train['최대구매액'].median()\n",
    "x_train.loc[conditionMaxBuyOutlier, '최대구매액많은편']=2\n",
    "x_train.loc[conditionMaxBuy, '최대구매액많은편']=1\n",
    "x_train.loc[conditionMaxBuySmall, '최대구매액많은편']=0\n",
    "\n",
    "## 파생변수- x_test\n",
    "conditionWeekend= x_test['주말방문비율']>0\n",
    "x_test.loc[conditionWeekend, '주말방문여부']= 1\n",
    "x_test.loc[~conditionWeekend, '주말방문여부']= 0\n",
    "\n",
    "conditionRefund= x_test['환불금액']>0\n",
    "x_test.loc[conditionRefund, '환불여부']= 1\n",
    "x_test.loc[~conditionRefund, '환불여부']= 0\n",
    "\n",
    "conditionMaxBuyOutlier= x_test['최대구매액']> maxB_test['최대구매액']\n",
    "conditionMaxBuy= (x_test['최대구매액']<= maxB_test['최대구매액']) & (x_test['최대구매액'] > x_test['최대구매액'].median())\n",
    "conditionMaxBuySmall= x_test['최대구매액'] <= x_test['최대구매액'].median()\n",
    "x_test.loc[conditionMaxBuyOutlier, '최대구매액많은편']=2\n",
    "x_test.loc[conditionMaxBuy, '최대구매액많은편']=1\n",
    "x_test.loc[conditionMaxBuySmall, '최대구매액많은편']=0\n",
    "\n",
    "## 메모리 관리. 변수 지우기\n",
    "x_train.drop(columns='환불금액', inplace=True)\n",
    "x_test.drop(columns='환불금액', inplace=True)\n",
    "\n",
    "## 책- 상관관계\n",
    "x_train.drop(columns='최대구매액', inplace=True)\n",
    "x_test.drop(columns='최대구매액', inplace=True)\n",
    "\n",
    "## 인코딩. 범주화\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder= LabelEncoder()\n",
    "x_train['주구매상품']= encoder.fit_transform(x_train['주구매상품']) # astype 바로 못 붙인다\n",
    "x_train['주구매지점']= encoder.fit_transform(x_train['주구매지점'])\n",
    "x_train['주구매상품']= x_train['주구매상품'].astype('category') # inplace 없다\n",
    "x_train['주구매지점']= x_train['주구매지점'].astype('category')\n",
    "x_train['주말방문여부']= x_train['주말방문여부'].astype('category')\n",
    "x_train['환불여부']= x_train['환불여부'].astype('category')\n",
    "x_train['최대구매액많은편']= x_train['최대구매액많은편'].astype('category')\n",
    "\n",
    "## 인코딩. 범주화- x_test\n",
    "x_test['주구매상품']= encoder.fit_transform(x_test['주구매상품'])\n",
    "x_test['주구매지점']= encoder.fit_transform(x_test['주구매지점'])\n",
    "x_test['주구매상품']= x_test['주구매상품'].astype('category')\n",
    "x_test['주구매지점']= x_test['주구매지점'].astype('category')\n",
    "x_test['주말방문여부']= x_test['주말방문여부'].astype('category')\n",
    "x_test['환불여부']= x_test['환불여부'].astype('category')\n",
    "x_test['최대구매액많은편']= x_test['최대구매액많은편'].astype('category')\n",
    "\n",
    "\n",
    "## 그냥 drop 시키고 cust_id 만 따로 저장\n",
    "x_train_custid= x_train['cust_id']\n",
    "x_train.drop(columns='cust_id', inplace=True)\n",
    "\n",
    "x_test_custid= x_test['cust_id']\n",
    "x_test.drop(columns='cust_id', inplace=True)\n",
    "\n",
    "## 스케일링 - 시험때는 조건말고 눈으로 보고 컬럼 골라내서 for 문 돌리자\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler= StandardScaler()\n",
    "x_trainNumCols= x_train.columns[(x_train.dtypes!=object) &(x_train.dtypes!='category')]\n",
    "bigNumCols= x_trainNumCols[x_train.describe().loc['max']> 30] # 30 근거: 범주컬럼 냅두고 싶어서 눈으로 정한 값\n",
    "for col in bigNumCols:\n",
    "    x_train[col]= scaler.fit_transform(x_train[[col]])\n",
    "    \n",
    "## 스케일링 - x_test\n",
    "x_testNumCols= x_test.columns[(x_test.dtypes!=object) &(x_test.dtypes!='category')]\n",
    "bigNumCols= x_testNumCols[x_train.describe().loc['max']> 30] # 30 근거: 범주컬럼 냅두고 싶어서 눈으로 정한 값\n",
    "for col in bigNumCols:\n",
    "    x_test[col]= scaler.fit_transform(x_test[[col]])\n",
    "    \n",
    "beforeModeling= time.time()\n",
    "print(f\"모델링전까지 수행시간: {beforeModeling-start_time:.6} sec\")\n",
    "\n",
    "## 모델링\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "## 메모리 이슈 -  여분이 7.9GB 인데 랜포 40으로 돌리면 8.5GB 를 드신다. 랜포말고 DecisionTree는?\n",
    "model= RandomForestClassifier(n_estimators= 10) # help(model) #fit # 메모리 줄이기. n_estimators=100 default. 10으로 해결.\n",
    "\n",
    "\n",
    "## id 가 포함된 채로 y_train 목표로 학습(fit)시킬 경우, y_test_predict 의 id 에는 중복값이 들어가있다. y_test_proba는 (2,2438,3500)이 되고.\n",
    "model.fit(x_train, y_train.iloc[:,1]) # y_test_predict 용 모델도 gender 만 넣고\n",
    "y_test_predict= model.predict(x_test) \n",
    "y_test_proba= model.predict_proba(x_test) # <<< 결과 제출용\n",
    "\n",
    "\n",
    "## help(pd.concat) # pd.concat([series1, series2], ignore_index=True, axis=1) # y_test_predict 는 ndarray\n",
    "# display(pd.concat([x_test_custid, pd.Series(y_test_predict)], ignore_index=True, axis=1)) \n",
    "\n",
    "## x_test_predict 와 x_test_proba 를 비교하여, proba 의 어느 열을 남길지 결정\n",
    "## > predict 값이 1(남자) 인 게, proba의 2번째 컬럼[1]\n",
    "## 데이터 설명에서 gender==1 이 남자.\n",
    "\n",
    "# print(f\"y_test_proba {y_test_proba} \\ny_test_proba[0] {y_test_proba[0]}\")\n",
    "# display(pd.DataFrame(y_test_proba).head()) # <<< columns=[0,1], 첫 행= [0.5, 0.5]\n",
    "# display(pd.DataFrame(y_test_proba).info())\n",
    "# display(pd.concat([ x_test_custid, pd.DataFrame(y_test_proba).iloc[:,1] ], axis=1).rename(columns={\"cust_id\":\"custid\", 1:\"gender\"}))\n",
    "genderManProba= pd.concat([ x_test_custid, pd.DataFrame(y_test_proba).iloc[:,1] ], axis=1).rename(columns={\"cust_id\":\"custid\", 1:\"gender\"})\n",
    "# print(y_train)\n",
    "\n",
    "# help(pd.DataFrame.to_csv) # index\n",
    "genderManProba.to_csv('data/김형준-1번-proba.csv', index=False)\n",
    "\n",
    "## score 는 필수사항은 아니므로 일단 보류\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "afterModeling= time.time()\n",
    "print(f\"모델링 시간: {afterModeling-beforeModeling:.6} sec\")\n",
    "print(f\"전체 수행 시간: {afterModeling-start_time:.6} sec\") # 노트북 빠를때 0.313999 sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "18a68f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(pd.concat) # pd.concat([s1, s2], ignore_index=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1dc81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637cee62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd8f7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  ####  ####  ####  ####  ####  ####  ####  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63551558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "554769cd",
   "metadata": {},
   "source": [
    "# 실제 시험환경에서 친 코드\n",
    "- https://dataq.goorm.io/exam/116674/%EC%B2%B4%ED%97%98%ED%95%98%EA%B8%B0/quiz/3\n",
    "> X_test['주구매지점']= encoder.fit_transform(X_test['주구매지점']) # 여기서 상품으로 바꿔야되는데 지점으로 냅뒀다. ctrl CV의 폐해\n",
    "\n",
    "- lightgbm 사용\n",
    "> 랜포로 돌렸을 때: 0.313999 sec <p>\n",
    "lightgbm 으로 돌렸을 때: 0.3529975 sec"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3e2c1d98",
   "metadata": {},
   "source": [
    "viewData() 만들었으면 train 만 보지 말고 test 까지 보렴\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1507247b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.2-py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in e:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (0.24.2)\n",
      "Requirement already satisfied: numpy in e:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.20.3)\n",
      "Requirement already satisfied: wheel in e:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.0)\n",
      "Requirement already satisfied: scipy in e:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in e:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef23c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cust_id  gender\n",
      "0        3500       0\n",
      "1        3501       0\n",
      "2        3502       0\n",
      "3        3503       0\n",
      "4        3504       0\n",
      "...       ...     ...\n",
      "2477     5977       1\n",
      "2478     5978       0\n",
      "2479     5979       0\n",
      "2480     5980       0\n",
      "2481     5981       0\n",
      "\n",
      "[2482 rows x 2 columns]\n",
      "실행시간 0.3529975 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time= time.time()\n",
    "# 출력을 원하실 경우 print() 함수 활용\n",
    "# 예시) print(df.head())\n",
    "\n",
    "# getcwd(), chdir() 등 작업 폴더 설정 불필요\n",
    "# 파일 경로 상 내부 드라이브 경로(C: 등) 접근 불가\n",
    "\n",
    "# 데이터 파일 읽기 예제\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',None)\n",
    "X_train= pd.read_csv('bigData/x_train.csv', encoding='CP949')\n",
    "y_train= pd.read_csv('bigData/y_train.csv', encoding='CP949')\n",
    "X_test= pd.read_csv('bigData/x_test.csv', encoding='CP949')\n",
    "\n",
    "## 데이터로드, null체크, 뭔가이상한거체크, 이상치~파생변수, 상관관계, 변수선택\n",
    "## 범주화, 스케일링\n",
    "## 모델링. lightgbm 써보기. 하이퍼파라미터 튜닝\n",
    "pd.set_option('display.max_columns',None) # 먹히는거 확인\n",
    "# help(pd)\n",
    "def viewData(n=2):\n",
    "\tprint('----  ----  X_train  ----  ----  ')\n",
    "\tprint(X_train.info(), X_train.head(n), X_train.tail(n))\n",
    "\tprint('----  ----  X_test  ----  ----  ')\n",
    "\tprint(X_test.info(), X_test.head(n), X_test.tail(n))\n",
    "\tprint('----  ----  y_train  ----  ----  ')\n",
    "\tprint(y_train.info(), y_train.head(n), y_train.tail(n))\n",
    "\n",
    "X_train_custid= X_train['cust_id'] #3500\n",
    "X_test_custid= X_test['cust_id'] #2482\n",
    "X_train.drop(columns='cust_id',inplace=True)\n",
    "X_test.drop(columns='cust_id',inplace=True)\n",
    "y_train.drop(columns='cust_id',inplace=True)\n",
    "\n",
    "# viewData()\n",
    "\n",
    "# print(X_train[X_train.isnull().sum(1)!=0])\n",
    "# print(X_train['환불금액'].describe())\n",
    "# print(X_train[X_train.isnull().sum(1)==0].describe()) # null 아닌 것중 min 이 0이 아니다\n",
    "X_train['환불금액'].fillna(0, inplace=True)\n",
    "X_test['환불금액'].fillna(0, inplace=True)\n",
    "\n",
    "# viewData()\n",
    "\n",
    "# print(X_train.columns[X_train.dtypes==object])\n",
    "# print(X_train.select_dtypes(include=object).columns)\n",
    "# print((X_train.corr()>0.6) | (X_train.corr()< -0.6)) # 총구매액이랑 공선성 걸리는 게 많다. 총구를 버리자\n",
    "X_train.drop(columns='총구매액', inplace=True)\n",
    "X_test.drop(columns='총구매액', inplace=True)\n",
    "\n",
    "# viewData()\n",
    "\n",
    "# from sklearn import preprocessing # print(dir(preprocessing))\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder= LabelEncoder()\n",
    "# help(encoder.fit_transform) # 정보가 거의 없다\n",
    "# print(type(encoder.fit_transform(X_train['주구매지점'])))\n",
    "X_train['주구매지점']= encoder.fit_transform(X_train['주구매지점'])\n",
    "X_test['주구매지점']= encoder.fit_transform(X_test['주구매지점'])\n",
    "\n",
    "# print(type(pd.get_dummies(X_train, drop_first=True))) # dataframe\n",
    "# X_train= pd.get_dummies(X_train, drop_first=True) #인자는 통째 넣어도 object만 골라주고, 반환은 DF.\n",
    "\n",
    "X_train['주구매상품']= encoder.fit_transform(X_train['주구매상품'])\n",
    "X_test['주구매상품']= encoder.fit_transform(X_test['주구매상품'])\n",
    "\n",
    "# X_test= pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "# viewData() #train 과 test 컬럼수가 다르다. get_dummies 문제가 좀 많은데?\n",
    "\n",
    "## 스케일링\n",
    "# from sklearn import preprocessing #print(dir(preprocessing))\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler= MinMaxScaler()\n",
    "# print(type(scaler.fit_transform(X_train[floatCols]))) #ndarray\n",
    "# print(scaler.fit_transform(X_train[floatCols]))\n",
    "# print(X_train.select_dtypes(include='float64').columns) #['환불금액', '내점당구매건수', '주말방문비율']\n",
    "floatCols= X_train.select_dtypes(include='float64').columns\n",
    "X_train[floatCols]= scaler.fit_transform(X_train[floatCols])\n",
    "X_train['최대구매액']= scaler.fit_transform(X_train[['최대구매액']]) # 최대구매액 int64 인데 빠트림\n",
    "\n",
    "floatCols= X_test.select_dtypes(include='float64').columns\n",
    "X_test[floatCols]= scaler.fit_transform(X_test[floatCols])\n",
    "X_test['최대구매액']= scaler.fit_transform(X_test[['최대구매액']]) # 최대구매액 int64 인데 빠트림\n",
    "\n",
    "# viewData() \n",
    "\n",
    "## test 도 섞어서 만들건지. model_selection. train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# help(train_test_split)\n",
    "\n",
    "## 모델링\n",
    "# import lightgbm # print(dir(lightgbm)) # LGBMClassifier\n",
    "# 좀더 큰 친구다 model= lightgbm() # help(lightgbm) #잘린다\n",
    "from lightgbm import LGBMClassifier\n",
    "# help(LGBMClassifier) #  max_depth: int = -1, learning_rate: float = 0.1, n_estimators: int = 100, random_state\n",
    "model= LGBMClassifier() # random_state= 10\n",
    "# viewData()\n",
    "model.fit(X_train, y_train.iloc[:,0]) # 1d array 를 원하네. 여기까지 정상 실행\n",
    "# help(model)\n",
    "y_train_predict= model.predict(X_train) # score 알아보는 용도\n",
    "y_test_predict= model.predict(X_test) # 제출용\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# help(roc_auc_score) #roc_auc_score(y, y_pred, average=None)\n",
    "# print(roc_auc_score(y_train, y_train_predict)) # 0.8589938430363963\n",
    "\n",
    "# print(type(y_test_predict)) # ndarray\n",
    "## 제출. 방법1\n",
    "# print(pd.concat([X_test_custid ,pd.Series(y_test_predict)], axis=1).rename(columns={0:'gender'}))\n",
    "\n",
    "## 제출. 방법2. 시험장에서 제시한 코드\n",
    "print(pd.DataFrame({'cust_id': X_test_custid, 'gender': y_test_predict}))\n",
    "\n",
    "\n",
    "# 답안 제출 참고\n",
    "# 아래 코드 예측변수와 수험번호를 개인별로 변경하여 활용\n",
    "# pd.DataFrame({'cust_id': X_test.cust_id, 'gender': pred}).to_csv('003000000.csv', index=False)\n",
    "\n",
    "print(f\"실행시간 {time.time() - start_time:.7} sec\") # 노트북 빠를 때 0.3529975 sec # 노트북 느릴때. 0.8639154 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ecdae91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7bea8",
   "metadata": {},
   "source": [
    "### 주석 싹 지우고 다시\n",
    "22.6.20 21:00 / x_test 에도 전처리 적용해야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e6938e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 데이터 로드, null, dtypes 체크 #이상치 체크, 인코딩, 파생변수 # 스케일링 # 모델링, train score, test score # 형식에 맞게 출력\n",
    "\n",
    "# ## gender 일 확률. proba\n",
    "# import time\n",
    "# start_time= time.time()\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_columns',None)\n",
    "# x_train= pd.read_csv('bigData/x_train.csv', encoding='CP949')\n",
    "# y_train= pd.read_csv('bigData/y_train.csv', encoding='CP949')\n",
    "# x_test= pd.read_csv('bigData/x_test.csv', encoding='CP949') # Wow! x_test 넣어야할 것을 x_train 넣었었다.\n",
    "\n",
    "# ## null 처리. 환불 null 은 환불이 없었다고 가정. fillna(0)\n",
    "# x_train['환불금액']= x_train['환불금액'].fillna(0)\n",
    "# x_test['환불금액']= x_test['환불금액'].fillna(0)\n",
    "\n",
    "# ## dtypes 체크 - 숫자인데 문자로 되어있는 건 아니 보인다\n",
    "\n",
    "# ## 이상치 보기. 구매액이 매우 크다고 해서 절삭하는 건 말이 안 된다고 본다.\n",
    "# def outlierCheck(data):\n",
    "#     dataNum= data.loc[:,data.dtypes!=object] # 숫자만\n",
    "#     desc= dataNum.describe()\n",
    "#     min1= desc.loc['min']\n",
    "#     max1= desc.loc['max']\n",
    "#     std= desc.loc['std']\n",
    "#     mean= desc.loc['mean']\n",
    "#     maxBoundary= mean+1.5*std\n",
    "#     minBoundary= mean-1.5*std\n",
    "    \n",
    "#     return minBoundary, maxBoundary\n",
    "\n",
    "# minB, maxB= outlierCheck(x_train)\n",
    "# minB_test, maxB_test= outlierCheck(x_test)\n",
    "\n",
    "# ## 파생변수. 주말방문 경험 유무? 1회 최대구매액 구간- boundary 밖 & median? 환불여부?\n",
    "# conditionWeekend= x_train['주말방문비율']>0\n",
    "# x_train.loc[conditionWeekend, '주말방문여부']= 1\n",
    "# x_train.loc[~conditionWeekend, '주말방문여부']= 0\n",
    "\n",
    "# conditionRefund= x_train['환불금액']>0\n",
    "# x_train.loc[conditionRefund, '환불여부']= 1\n",
    "# x_train.loc[~conditionRefund, '환불여부']= 0\n",
    "\n",
    "# conditionMaxBuyOutlier= x_train['최대구매액']> maxB['최대구매액']\n",
    "# conditionMaxBuy= (x_train['최대구매액']<= maxB['최대구매액']) & (x_train['최대구매액'] > x_train['최대구매액'].median())\n",
    "# conditionMaxBuySmall= x_train['최대구매액'] <= x_train['최대구매액'].median()\n",
    "# x_train.loc[conditionMaxBuyOutlier, '최대구매액많은편']=2\n",
    "# x_train.loc[conditionMaxBuy, '최대구매액많은편']=1\n",
    "# x_train.loc[conditionMaxBuySmall, '최대구매액많은편']=0\n",
    "\n",
    "# ## 파생변수- x_test\n",
    "# conditionWeekend= x_test['주말방문비율']>0\n",
    "# x_test.loc[conditionWeekend, '주말방문여부']= 1\n",
    "# x_test.loc[~conditionWeekend, '주말방문여부']= 0\n",
    "\n",
    "# conditionRefund= x_test['환불금액']>0\n",
    "# x_test.loc[conditionRefund, '환불여부']= 1\n",
    "# x_test.loc[~conditionRefund, '환불여부']= 0\n",
    "\n",
    "# conditionMaxBuyOutlier= x_test['최대구매액']> maxB_test['최대구매액']\n",
    "# conditionMaxBuy= (x_test['최대구매액']<= maxB_test['최대구매액']) & (x_test['최대구매액'] > x_test['최대구매액'].median())\n",
    "# conditionMaxBuySmall= x_test['최대구매액'] <= x_test['최대구매액'].median()\n",
    "# x_test.loc[conditionMaxBuyOutlier, '최대구매액많은편']=2\n",
    "# x_test.loc[conditionMaxBuy, '최대구매액많은편']=1\n",
    "# x_test.loc[conditionMaxBuySmall, '최대구매액많은편']=0\n",
    "\n",
    "# ## 메모리 관리. 변수 지우기\n",
    "# x_train.drop(columns='환불금액', inplace=True)\n",
    "# x_test.drop(columns='환불금액', inplace=True)\n",
    "\n",
    "# ## 책- 상관관계\n",
    "# x_train.drop(columns='최대구매액', inplace=True)\n",
    "# x_test.drop(columns='최대구매액', inplace=True)\n",
    "\n",
    "# ## 인코딩. 범주화\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# encoder= LabelEncoder()\n",
    "# x_train['주구매상품']= encoder.fit_transform(x_train['주구매상품']) # astype 바로 못 붙인다\n",
    "# x_train['주구매지점']= encoder.fit_transform(x_train['주구매지점'])\n",
    "# x_train['주구매상품']= x_train['주구매상품'].astype('category') # inplace 없다\n",
    "# x_train['주구매지점']= x_train['주구매지점'].astype('category')\n",
    "# x_train['주말방문여부']= x_train['주말방문여부'].astype('category')\n",
    "# x_train['환불여부']= x_train['환불여부'].astype('category')\n",
    "# x_train['최대구매액많은편']= x_train['최대구매액많은편'].astype('category')\n",
    "\n",
    "# ## 인코딩. 범주화- x_test\n",
    "# x_test['주구매상품']= encoder.fit_transform(x_test['주구매상품'])\n",
    "# x_test['주구매지점']= encoder.fit_transform(x_test['주구매지점'])\n",
    "# x_test['주구매상품']= x_test['주구매상품'].astype('category')\n",
    "# x_test['주구매지점']= x_test['주구매지점'].astype('category')\n",
    "# x_test['주말방문여부']= x_test['주말방문여부'].astype('category')\n",
    "# x_test['환불여부']= x_test['환불여부'].astype('category')\n",
    "# x_test['최대구매액많은편']= x_test['최대구매액많은편'].astype('category')\n",
    "\n",
    "\n",
    "# ## 그냥 drop 시키고 cust_id 만 따로 저장( 'cust_id 를 index 로 만들' - 이 방법이 좀 문제를 일으키는 것 같아서 )\n",
    "# # train 에 index 떼고 y_train 을 id 째 넣어도 여전히 안된다\n",
    "# # 나중에 되돌리는 건 df.reset_index(drop=False, inplace=True)\n",
    "# x_train_custid= x_train['cust_id'] # x_train.index= x_train['cust_id']\n",
    "# x_train.drop(columns='cust_id', inplace=True)\n",
    "\n",
    "# x_test_custid= x_test['cust_id'] #x_test.index= x_test['cust_id']\n",
    "# x_test.drop(columns='cust_id', inplace=True)\n",
    "\n",
    "# ## 스케일링 - 시험때는 조건말고 눈으로 보고 컬럼 골라내서 for 문 돌리자\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler= StandardScaler()\n",
    "# x_trainNumCols= x_train.columns[(x_train.dtypes!=object) &(x_train.dtypes!='category')]\n",
    "# bigNumCols= x_trainNumCols[x_train.describe().loc['max']> 30] # 30 근거: 범주컬럼 냅두고 싶어서 눈으로 정한 값\n",
    "# for col in bigNumCols:\n",
    "#     x_train[col]= scaler.fit_transform(x_train[[col]])\n",
    "    \n",
    "# ## 스케일링 - x_test\n",
    "# x_testNumCols= x_test.columns[(x_test.dtypes!=object) &(x_test.dtypes!='category')]\n",
    "# bigNumCols= x_testNumCols[x_train.describe().loc['max']> 30] # 30 근거: 범주컬럼 냅두고 싶어서 눈으로 정한 값\n",
    "# for col in bigNumCols:\n",
    "#     x_test[col]= scaler.fit_transform(x_test[[col]])\n",
    "    \n",
    "# beforeModeling= time.time()\n",
    "# print(f\"모델링전까지 수행시간: {beforeModeling-start_time:.6} sec\")\n",
    "\n",
    "# ## 모델링\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model= RandomForestClassifier(n_estimators= 10) # help(model) #fit # 메모리 줄이기. n_estimators=100 default. 10으로 해결.\n",
    "\n",
    "# # display(x_train.head())\n",
    "# # print(x_train.shape, x_test.shape) # 둘다 (3500,10). x_test 가 왜 3500? 원래 (2482,10) 인데\n",
    "# # print(x_train.columns, x_test.columns) # 컬럼 일치\n",
    "# # print(\"y_train.shape: \", y_train.shape) #(3500, 2) . 정상적으로 2컬럼.\n",
    "# # print(\"y_train.iloc[:,1]: \", y_train.iloc[:,1])\n",
    "\n",
    "\n",
    "# ## 메모리 이슈 -  여분이 7.9GB 인데 랜포 돌리면 8.5GB 를 드신다. PC에서 돌리면 돌아갈까? 랜포말고 DecisionTree는?\n",
    "# # n_estimators=10 으로 해결. # n_estimators=40 에서 재발- MemoryError: could not allocate 458752000 bytes. 437MB\n",
    "\n",
    "# ## train 에 index 넣는 게 좀 문제 있어 보여서 cust_id 그냥 drop 시키고 진행\n",
    "# ## predict 는 슬라이싱 하지 말아야 하고\n",
    "# # id 가 꼬이게 된다. model.fit(x_train, y_train) #display(pd.DataFrame(y_train_predict).head()) # <<< 2열 (인덱스,예측 결과값)\n",
    "# model.fit(x_train, y_train.iloc[:,1]) # y_test_predict 용 모델도 gender 만 넣고\n",
    "# y_test_predict= model.predict(x_test) \n",
    "\n",
    "# ## proba 는 슬라이싱 해서 gender 만 내도록 해야 한다.\n",
    "# model.fit(x_train, y_train.iloc[:,1]) # <<< 없는 cust_id 가 방해가 되나 싶어서 1열만 내도록 학습\n",
    "# y_test_proba= model.predict_proba(x_test) # <<< train 으로 만든 모델에 x_test 넣기. 결과 제출용으로 필수\n",
    "\n",
    "# # y_train_predict= model.predict(x_train) # <<< score 는 보류\n",
    "\n",
    "# # display(pd.DataFrame(y_test_predict).head())\n",
    "# ## help(pd.concat) # pd.concat([series1, series2], ignore_index=True, axis=1)\n",
    "# display(pd.concat([x_test_custid, pd.Series(y_test_predict)], ignore_index=True, axis=1)) # y_test_predict 는 ndarray\n",
    "\n",
    "# ## id 가 포함된 채로 y_train 목표로 학습(fit)시킬 경우, y_test_predict 의 id 에는 중복값이 들어가있다.\n",
    "# # display(pd.DataFrame(y_test_predict).sort_values(0, ascending=True).head())\n",
    "\n",
    "# # print(f\"len(y_test_predict) {len(y_test_predict)}\")\n",
    "# # print(f\"y_test_predict {y_test_predict}\")\n",
    "# print(f\"y_test_proba {y_test_proba} \\ny_test_proba[0] {y_test_proba[0]}\")\n",
    "# # print(f\"len(y_test_proba) {len(y_test_proba)} \\nlen(y_test_proba[0]) {len(y_test_proba[0])}\")\n",
    "# # print(f\"y_test_proba {y_test_proba} \\ny_test_proba[0] {y_test_proba[0]} \\ny_test_proba[0][0] {y_test_proba[0][0]}\")\n",
    "\n",
    "# ## y_train 에 index가 있으면 빼고 학습시켜야 proba가 정상적으로 나온다\n",
    "# # 해결! ValueError: could not broadcast input array from shape (3500,3500) into shape (3500,)\n",
    "# display(pd.DataFrame(y_test_proba).head()) # <<< columns=[0,1], 첫 행= [0.5, 0.5]\n",
    "# display(pd.DataFrame(y_test_proba).info())\n",
    "\n",
    "# # print(f\"y_test_proba {y_test_proba} \\ny_test_proba[0] {y_test_proba[0]} \\ny_test_proba[0][0]\\\n",
    "# #     {y_test_proba[0][0]}\")\n",
    "\n",
    "# # print(f\"len(y_test_proba) {len(y_test_proba)} \\nlen(y_test_proba[0]) {len(y_test_proba[0])}  \\\n",
    "# #     \\nlen(y_test_proba[0][0]) {len(y_test_proba[0][0])}\")\n",
    "\n",
    "# # # help(pd.DataFrame) # example. df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), columns=['a', 'b', 'c'])\n",
    "# # print(pd.DataFrame(data=y_test_proba, columns=['custid', 'gender'])) \n",
    "\n",
    "\n",
    "# ## score 는 필수사항은 아니므로 일단 보류\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# # y_test 는 애초에 없다. print(roc_auc_score(y_test, y_test_predict))\n",
    "# #ValueError: multiclass-multioutput format is not supported. 보류\n",
    "# # 내가 만든 모델(y_train_predict)의 점수만 확인 가능. \n",
    "# # print(roc_auc_score(y_train, pd.DataFrame(data=y_train_predict, columns=['cust_id', 'gender'])) )\n",
    "\n",
    "\n",
    "# # afterModeling= time.time()\n",
    "# # print(f\"모델링 시간: {afterModeling-beforeModeling:.6} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a55acc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c732523b",
   "metadata": {},
   "source": [
    "### 각종 시행착오 및 주석 포함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e58dd4",
   "metadata": {},
   "source": [
    "1. loc에 컬럼 여럿 print(x_train.describe().loc[:,('총구매액', '환불금액')])\n",
    "2. print 대신 display 로 보면 값-컬럼 정렬되있어서 보기 좋다\n",
    "3. [column rename python](https://rfriend.tistory.com/468) 특정 컬럼만 콕 집어 바꿀 수 있다.  df.rename(columns = {\"old\": \"new\"}, inplace = True)\n",
    "4. 메모리 부족 에러: 코랩이든 남의 컴이든 똑같을 것. 변수 개수 줄이고 각종 중간 변수들 생략하고, 에러나도 메모리 해제하게끔 조치해보자. \n",
    "> n_estimators=100 대신 40 넣고, OS 상의 다른 서비스 끄고, 변수 줄여서 성공. 파이썬에 메모리 해제하는 코드는 없대\n",
    "4. 랜덤포레스트 에서 model.score() 시, \"ValueError: X has 2 features, but DecisionTreeClassifier is expecting 10 features as input\"\n",
    "> 랜포에 왠 Decision.. 일단 따지지 않고 model.score() 안 쓰고 sklearn.metrics: roc_auc_score 쓰는걸로 임시방편\n",
    "5. [ValueError: could not convert string to float: '기타'](https://hashcode.co.kr/questions/9650/valueerror-could-not-convert-string-to-float-%EB%AC%B8%EC%9E%90-%EB%9D%BC%EB%8A%94-%EC%97%90%EB%9F%AC). 기타 컬럼의 string 에 숫자 연산이 필요한 무언가를 했을 것\n",
    "> x_train, y_train, x_test 에 모두 '기타' 컬럼이 존재하지 않는다. 아마 LabelEncoding 이 필요한 '주구매상품, 주구매지점' 에 연산을 하다가 가장 처음 만난 요소가 '주구매상품:기타' 일 것.\n",
    "- x_test 에도 x_train 에 했던 것을 똑같이 해줘야 한다는 건데.. x_validation 넣으면 또 안될거 아녀\n",
    "> 시험 혹은 채점자의 검증은 y_test 와 일치여부만을 본다. x_validation 이 만약에 있다면 그 또한 전처리해서 모델러가 사용할 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4039a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?????? '기타' 라는 컬럼이 없는데 어디서 나온 컬럼이여-\n",
    "# print(x_train.columns, x_test.columns, y_train.columns)\n",
    "# data= pd.read_csv('bigData/x_train.csv', encoding='CP949')\n",
    "# data['주구매상품'].value_counts() # 여기에 '기타' 있다. 가장 많은 유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2cafad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 데이터 로드, null, dtypes 체크 #이상치 체크, 인코딩, 파생변수 # 스케일링 # 모델링, train score, test score # 형식에 맞게 출력\n",
    "# ## gender 일 확률. proba\n",
    "\n",
    "\n",
    "# # !ls\n",
    "# import time\n",
    "# start_time= time.time()\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_columns',None)\n",
    "\n",
    "# # help(pd.read_csv) # encoding #UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 8: invalid continuation byte\n",
    "# x_train= pd.read_csv('bigData/x_train.csv', encoding='CP949')\n",
    "# y_train= pd.read_csv('bigData/y_train.csv', encoding='CP949')\n",
    "# x_test= pd.read_csv('bigData/x_train.csv', encoding='CP949')\n",
    "# # display(type(x_train))\n",
    "# # display(x_train.shape, x_train.info(). x_train.head(2)) # AttributeError: 'NoneType' object has no attribute 'x_train'\n",
    "# # info() 뒤에 , 대신 . 을 찍었다\n",
    "# # display(x_train.shape, x_train.info(), x_train.head(2)) # 총 3500개. 환불금액 1205개. 주구매상품 주구매지점 object\n",
    "# # display(y_train.shape, y_train.info(), y_train.head(2)) # cust_id, gender. 제출형식에는 _ 없음에 유의\n",
    "# # display(x_test.shape, x_test.info(), x_test.head(2)) # 총 3500개. train-test 가 반반이네.\n",
    "\n",
    "# ## null 처리. 환불 null 은 환불이 없었다고 가정. fillna(0)\n",
    "# # display(x_train['환불금액'].min() ,'---') # min: 5600. null 이 아닌 것 중 0인 것은 없다\n",
    "# # 틀림 x_train.loc[x_train.isnull().sum()!=0]\n",
    "# # display(x_train.loc[x_train.isnull().sum(1) !=0],'---')\n",
    "# # display(x_train.describe().loc[:,('총구매액', '환불금액')],'---')\n",
    "# # 환불금액이 null 인 것의 의미? 가정1. 적지 않았다. 가정2. 환불이 없었다. - 2295 개나 적지 않았다는걸 받아들이기 어려움\n",
    "# # 환불금액을 mean 값으로 대체할 경우 문제점: 총구매액보다 커질 수 있다.\n",
    "# x_train['환불금액']= x_train['환불금액'].fillna(0)\n",
    "# # display(x_train.loc[x_train.isnull().sum(1)!=0].describe(),'---')\n",
    "# # display(y_train.loc[x_train.isnull().sum(1)!=0],'---') # y_train 에는 null 이 없다\n",
    "\n",
    "# ## dtypes 체크 - 숫자인데 문자로 되어있는 건 아니 보인다\n",
    "# # display(x_train.columns[x_train.dtypes==object])\n",
    "# # display(x_train.loc[:,x_train.dtypes==object].iloc[:,0].value_counts().count()) # 42종 카테고리\n",
    "# # display(x_train.loc[:,x_train.dtypes==object].iloc[:,1].value_counts().count()) # 24종 카테고리\n",
    "# # display(x_train.columns[x_train.dtypes!=object])\n",
    "# # display(x_train.loc[:,x_train.dtypes!=object])\n",
    "# # display(x_train.describe())\n",
    "\n",
    "# ## 이상치 보기. 구매액이 매우 크다고 해서 절삭하는 건 말이 안 된다고 본다.\n",
    "# # 대신 boundary 바깥의 값을 파생변수에 이용할 수도?\n",
    "# def outlierCheck(data):\n",
    "#     dataNum= data.loc[:,data.dtypes!=object] # 숫자만\n",
    "    \n",
    "#     desc= dataNum.describe()\n",
    "#     min1= desc.loc['min']\n",
    "#     max1= desc.loc['max']\n",
    "#     std= desc.loc['std']\n",
    "#     mean= desc.loc['mean']\n",
    "#     maxBoundary= mean+1.5*std\n",
    "#     minBoundary= mean-1.5*std\n",
    "# #     print(\"maxBoundary\", maxBoundary, '---')\n",
    "# #     print(\"minBoundary\", minBoundary, '---')\n",
    "    \n",
    "# #     print((dataNum>maxBoundary).sum(0), '---') # 큰 이상치 수백개\n",
    "# #     print((dataNum<minBoundary).sum(0), '---') # 작은 이상치 없음\n",
    "    \n",
    "#     return minBoundary, maxBoundary\n",
    "\n",
    "# minB, maxB= outlierCheck(x_train)\n",
    "\n",
    "# ## 파생변수. 주말방문 경험 유무? 1회 최대구매액 구간- boundary 밖 & median? 환불여부?\n",
    "# # 주말방문여부, 환불여부, 최대구매액많은편\n",
    "# # display(x_train.head(3))\n",
    "# conditionWeekend= x_train['주말방문비율']>0\n",
    "# x_train.loc[conditionWeekend, '주말방문여부']= 1\n",
    "# x_train.loc[~conditionWeekend, '주말방문여부']= 0\n",
    "# # display(x_train['내점일수'].value_counts(), '---')\n",
    "# # display(x_train['구매주기'].count(), '---')\n",
    "# # display(x_train[x_train['구매주기']<=4].count(), '---') # 기준값 모르겠다\n",
    "# # display(x_train.describe().loc[:,('총구매액','최대구매액','환불금액')], '---')\n",
    "# conditionRefund= x_train['환불금액']>0\n",
    "# x_train.loc[conditionRefund, '환불여부']= 1\n",
    "# x_train.loc[~conditionRefund, '환불여부']= 0\n",
    "# # print(maxB)\n",
    "# conditionMaxBuyOutlier= x_train['최대구매액']> maxB['최대구매액']\n",
    "# conditionMaxBuy= (x_train['최대구매액']<= maxB['최대구매액']) & (x_train['최대구매액'] > x_train['최대구매액'].median())\n",
    "# conditionMaxBuySmall= x_train['최대구매액'] <= x_train['최대구매액'].median()\n",
    "# x_train.loc[conditionMaxBuyOutlier, '최대구매액많은편']=2\n",
    "# x_train.loc[conditionMaxBuy, '최대구매액많은편']=1\n",
    "# x_train.loc[conditionMaxBuySmall, '최대구매액많은편']=0\n",
    "\n",
    "# # display(x_train.head(), '---')\n",
    "# # display(x_train['최대구매액많은편'].value_counts()) # 2는 207개\n",
    "\n",
    "# ## 메모리 관리. 변수 지우기\n",
    "# x_train.drop(columns='환불금액', inplace=True)\n",
    "\n",
    "# ## 책- 상관관계\n",
    "# # display((x_train.corr() < -0.7) |(x_train.corr()>0.7))\n",
    "# # => (총구매액~최대구매액) , (최대구매액많은편~최대구매액) 의 상관관계가 0.7 초과이므로, 최대구매액을 없애자\n",
    "# x_train.drop(columns='최대구매액', inplace=True)\n",
    "# # display((x_train.corr() < -0.7) |(x_train.corr()>0.7)) # 더이상 다중공선성 문제있는 것은 없다\n",
    "# # display(x_train.head(), '---')\n",
    "\n",
    "# ## 인코딩. 범주화\n",
    "# # display(x_train.columns[x_train.dtypes==object], '---') # ['주구매상품', '주구매지점']\n",
    "# # import sklearn # help(sklearn)\n",
    "# # from sklearn import preprocessing # dir(preprocessing) # LabelEncoder\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# # help(LabelEncoder) # examples #fit_transform(self, y)\n",
    "# encoder= LabelEncoder()\n",
    "# # print(type(encoder.fit_transform(x_train['주구매상품']))) # ndarray. inplace 없다\n",
    "# x_train['주구매상품']= encoder.fit_transform(x_train['주구매상품']) # astype 바로 못 붙인다\n",
    "# x_train['주구매지점']= encoder.fit_transform(x_train['주구매지점'])\n",
    "# x_train['주구매상품']= x_train['주구매상품'].astype('category') # inplace 없다\n",
    "# x_train['주구매지점']= x_train['주구매지점'].astype('category')\n",
    "# # 파생변수 범주화\n",
    "# x_train['주말방문여부']= x_train['주말방문여부'].astype('category')\n",
    "# x_train['환불여부']= x_train['환불여부'].astype('category')\n",
    "# x_train['최대구매액많은편']= x_train['최대구매액많은편'].astype('category')\n",
    "\n",
    "\n",
    "# # display(x_train.dtypes, x_train.head(), '---')\n",
    "\n",
    "# ## cust_id 를 custid 로 변경하고 index 로 만들기\n",
    "# # print(y_train.head())\n",
    "# # y_train 은 cust_id 로 되어 있어서, 미리 변경하지 말고 to_csv 하기 직전에 바꾸자 <<\n",
    "# ## 나중에 되돌리는 건 df.reset_index(drop=False, inplace=True)\n",
    "# # y_train 으로 보내야 하니 버릴 수는 없고, \n",
    "# # help(x_train) # rename( . df.rename(columns={\"A\": \"a\", \"B\": \"c\"}, inplace=Ture)\n",
    "# # x_train.rename(columns={\"cust_id\":\"custid\"}, inplace=True) # 콜론!\n",
    "# # print(x_train.columns[0])\n",
    "# # print(x_train.columns[1::])\n",
    "# # print(x_train.columns, '---')\n",
    "# x_train.index= x_train['cust_id']\n",
    "# x_train.drop(columns='cust_id', inplace=True)\n",
    "\n",
    "# # display(x_train.head(), x_train.dtypes, '---')\n",
    "\n",
    "\n",
    "# ## 스케일링 - 시험때는 조건말고 눈으로 보고 컬럼 골라내서 for 문 돌리자\n",
    "# # + 조건으로 거니까 앞에 코드에서 변경이 있어도, 최소 변경만으로 수월하게 진행가능\n",
    "# # from sklearn import preprocessing # dir(preprocessing) # gender는 범주형이니, StandardScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler= StandardScaler()\n",
    "# x_trainNumCols= x_train.columns[(x_train.dtypes!=object) &(x_train.dtypes!='category')]\n",
    "# # print(x_trainNumCols)\n",
    "# # print(x_trainNumCols[x_train.describe().loc['max']> 10000])\n",
    "# bigNumCols= x_trainNumCols[x_train.describe().loc['max']> 30] # 30 근거: 범주컬럼 냅두고 싶어서 눈으로 정한 값\n",
    "# # scaler.fit_transform()\n",
    "# for col in bigNumCols:\n",
    "#     x_train[col]= scaler.fit_transform(x_train[[col]])\n",
    "    \n",
    "# # display(x_train.head(), x_train.dtypes, '---')\n",
    "\n",
    "# beforeModeling= time.time()\n",
    "# print(f\"모델링전까지 수행시간: {beforeModeling-start_time:.6} sec\")\n",
    "\n",
    "# ## 모델링\n",
    "# # import sklearn # help(sklearn) #package. ensemble\n",
    "# # from sklearn import ensemble # dir(ensemble) #RandomForestClassifier - gender\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model= RandomForestClassifier(n_estimators= 40) # help(model) #fit # 메모리 줄이기. n_estimators=100 default\n",
    "# # print(y_train.head()) # y_train 이 확률값이 아니다 ! 모델은 값으로 만들고 나중에 제출할 때만 _proba 해야!\n",
    "\n",
    "# ## 메모리 이슈\n",
    "# # 에러! MemoryError: could not allocate 458752000 byte= 437MB. 여유분 약 3GB\n",
    "# # MemoryError: could not allocate 229376000 bytes= 218MB\n",
    "# # model.fit_transform(x_train, y_train) # RandomForestClassifier 에 fit_transform 이 없다.\n",
    "\n",
    "# model.fit(x_train, y_train) # <<<\n",
    "\n",
    "# # 틀림. proba는 제출할때. y_train_proba= model.predict_proba(x_train) \n",
    "# # 여태 만진 게 train인데 왜 갑자기 test를. 굳이 train ㄴㄴ. 바로 test ㄱㄱ. y_train_predict= model.predict(x_train)\n",
    "# # 에러 y_test_predict= model.predict(x_test) # ValueError: could not convert string to float: '기타'\n",
    "\n",
    "# y_train_predict= model.predict(x_train) # <<<\n",
    "# y_test_predict= model.predict(x_test) # <<< train 으로 만든 모델에 x_test 넣기. roc_auc_score 뽑으려면 필수.\n",
    "# # 당연히 에러나겠지. 파생변수 없고 null 이 그득해서.\n",
    "\n",
    "# display(pd.DataFrame(y_train_predict).head()) # <<<\n",
    "\n",
    "# # print(model.score(y_train, y_train_predict)) # <<<\n",
    "# # Error: ValueError: X has 2 features, but DecisionTreeClassifier is expecting 10 features as input\n",
    "# # 랜포에 왠 의사결정나무.?? 따지지 말고 model.score 를 쓰지 말자.\n",
    "\n",
    "# # from sklearn import metrics # dir(metrics) # roc_auc_score\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# # help(roc_auc_score) #roc_auc_score(y, clf.predict_proba(X)[:, 1])\n",
    "# print(roc_auc_score(y_test, y_test_predict))\n",
    "\n",
    "\n",
    "# afterModeling= time.time()\n",
    "# print(f\"모델링 시간: {afterModeling-beforeModeling:.7} sec\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf42a02",
   "metadata": {},
   "source": [
    "[Memory Error 해결방법](https://bskyvision.com/799)\n",
    "114688000 byte(109 MB) 까지 줄였다\n",
    "1. 재실행 및 재부팅 후 실행 -> 마찬가지\n",
    "2. batch 사이즈 줄이기 -> n_estimators, max_depth 정도?\n",
    "> n_estimators=40\n",
    "3. 도중에 중단되도 메모리 해제하기 -> 파이썬에는 메모리 관리 명령어가 없다 (!!)\n",
    "> [python try except finally memory leak](https://stackoverflow.com/a/60454634)\n",
    "4. 변수를 줄인다 -> 파생변수를 지우거나 원본변수를 지우거나\n",
    "> 최대구매금액, 환불금액 삭제\n",
    "5. 내 PC에서 메모리를 먹고 있는 다른 서비스 종료\n",
    "6. 페이징 파일을 증가시킨다 -> 내 PC에서는 가능하더라도, 시험장에서는 .?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2819413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# help(RandomForestClassifier) \n",
    "#(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "# min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "# min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, \n",
    "#n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, \n",
    "# max_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df8da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab569f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eabde3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
