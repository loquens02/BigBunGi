{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae1f942",
   "metadata": {},
   "source": [
    "# 빅분기Part4-작업1유형-복잡한 데이터 분석\n",
    "상세한 요구조건"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1aed5",
   "metadata": {},
   "source": [
    "22.6.18.토 / 권장 ~p.345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c85fcc0",
   "metadata": {},
   "source": [
    "[이상치 하한, 상한 일괄적용](https://pandas.pydata.org/docs/reference/api/pandas.Series.clip.html) df['..'].clip(하한, 상한)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8796c4d",
   "metadata": {},
   "source": [
    "### 2.1 그룹별 집계/요약하기\n",
    "p.341 / boston. TAX컬럼이 TAX 중위값보다 큰 데이터 중. CHAS 컬럼과 RAD 컬럼 순으로 그룹 짓고. 각 그룹의 데이터 개수 구하기. 단, CHAS 와 RAD 컬럼별 데이터 개수는 COUNT 라는 컬럼으로 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c990873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          COUNT\n",
      "CHAS RAD       \n",
      "0    1        3\n",
      "     2        2\n",
      "     3        5\n",
      "     4       33\n",
      "     5       51\n",
      "     6       17\n",
      "     24     124\n",
      "1    5        7\n",
      "     24       8\n"
     ]
    }
   ],
   "source": [
    "# 책 참고\n",
    "import pandas as pd\n",
    "data= pd.read_csv('bigData/boston.csv')\n",
    "newdata= data[data['TAX']> data['TAX'].median()][['CHAS','RAD']] # 각 그룹 => 얘네만 본다.\n",
    "# print(newdata) \n",
    "# print(newdata['CHAS'].unique())\n",
    "# print(newdata['RAD'].unique())\n",
    "# help(newdata.groupby) # example 에도 없는 용법. groupby(['기준컬럼'])['대상컬럼'].작업()n\n",
    "\n",
    "## 2개로 기준잡은 group 이라서 둘중 뭐로 해도 count() 결과는 같다\n",
    "## count 세는 값 위에 '컬럼명'이 비어있다. 이걸 COUNT 로 채우는 것\n",
    "# print(newdata.groupby(['CHAS', 'RAD'])['CHAS'].count())\n",
    "# 같음 print(newdata.groupby(['CHAS', 'RAD'])['RAD'].count()) \n",
    "# 틀림 print(newdata.groupby(['CHAS', 'RAD'])['CHAS','RAD'].count()) # 같은 count 열이 2개 나온다. deprecated\n",
    "\n",
    "groupCntCR= newdata.groupby(['CHAS','RAD'])['CHAS'].count()\n",
    "# 안된다 groupCntCR.columns= 'COUNT'\n",
    "# 에러! Series에는 columns가 없다 print(groupCntCR.columns) \n",
    "\n",
    "# print(type(groupCntCR)) # Series\n",
    "# help(groupCntCR) # rename\n",
    "# 안된다. 밑에 이름이 바뀜 groupCntCR.rename('COUNT', inplace=True)\n",
    "# print(groupCntCR)\n",
    "\n",
    "# 발상의 전환. 없으면 만들라\n",
    "dfCR= pd.DataFrame(groupCntCR)\n",
    "#Index(...) must be called with a collection of some kind  #dfCR.columns= 'COUNT'\n",
    "dfCR.columns= ['COUNT']\n",
    "print(dfCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abb14a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CRIM   ZN  INDUS  NOX   RM  AGE  DIS  TAX  PTRATIO    B  LSTAT  MEDV\n",
      "CHAS RAD                                                                      \n",
      "0    1       3    3      3    3    3    3    3    3        3    3      3     3\n",
      "     2       2    2      2    2    2    2    2    2        2    2      2     2\n",
      "     3       5    5      5    5    5    5    5    5        5    5      5     5\n",
      "     4      33   33     33   33   32   33   33   33       33   33     33    33\n",
      "     5      51   51     51   51   48   51   51   51       51   51     51    51\n",
      "     6      17   17     17   17   16   17   17   17       17   17     17    17\n",
      "     24    124  124    124  124  122  124  124  124      124  124    124   124\n",
      "1    5       7    7      7    7    7    7    7    7        7    7      7     7\n",
      "     24      8    8      8    8    8    8    8    8        8    8      8     8\n"
     ]
    }
   ],
   "source": [
    "# 헤멤\n",
    "import pandas as pd\n",
    "data=pd.read_csv('bigData/boston.csv')\n",
    "# help(data.groupby) # exam. df.groupby(['Animal']).mean()\n",
    "print(data[data['TAX']> data['TAX'].median()].groupby(['CHAS','RAD']).count())\n",
    "# ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9474a194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b339c9a",
   "metadata": {},
   "source": [
    "### 2.2 오름차순/내림차순 정렬하기\n",
    "p.349 / boston 데이터. TAX 컬럼 오름차순 정렬 결과랑 내림차순 정렬 결과 각각 구하기. 각 순번에 맞는 오름차순 값과 내림차순 값의 차이를 구하여 분산값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dadd1577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101954.72475247525\n",
      "101954.72475247525\n",
      "28490.5986459515\n"
     ]
    }
   ],
   "source": [
    "# 책 (p.352) 참조. index 가 뒤섞였으면 다시 만들면 된다!\n",
    "import pandas as pd\n",
    "data= pd.read_csv('bigData/boston.csv')\n",
    "ascTAX= data['TAX'].sort_values(ascending=True); #print(ascTAX) # 오름\n",
    "desTAX= data['TAX'].sort_values(ascending=False); #print(desTAX)# 내림\n",
    "# help(ascTAX) #_index. reset_index(self, level=None, drop=False, name=None, inplace=False)\n",
    "# drop: False: 새 DataFrame에 열로 삽입하지 않고 인덱스를 재설정하기만 하면 됩니다.\n",
    "# drop: True: (책) 기존 index 정보를 남기지 않고 삭제하겠다\n",
    "ascTAX.reset_index(drop=True, inplace=True)\n",
    "desTAX.reset_index(drop=True, inplace=True)\n",
    "# print(ascTAX) # 오름\n",
    "# print(desTAX)# 내림\n",
    "# print(ascTAX-desTAX) # 의도대로 뺄셈이 잘 되었다. index 가 같아야 연산이 제대로 되는 구나!\n",
    "\n",
    "## 분산 구하기\n",
    "# print((ascTAX-desTAX).var()) # 101954.72475247525\n",
    "# print((desTAX-ascTAX).var()) # 101954.72475247525\n",
    "print(abs(desTAX-ascTAX).var()) # 101954.72475247525\n",
    "\n",
    "\n",
    "## 그냥 concat 써보기\n",
    "# 오름/내림차순 합치기\n",
    "# help(pd.concat) # exam. pd.concat([s1, s2])\n",
    "#(objs: 'Iterable[NDFrame] | Mapping[Hashable, NDFrame]', axis=0, join='outer', ignore_index: 'bool' = False,\n",
    "# keys=None, levels=None, names=None, verify_integrity: 'bool' = False, sort: 'bool' = False, copy: 'bool' = True) \n",
    "# taxCon= pd.concat([ascTAX, desTAX])\n",
    "taxCon= pd.concat([ascTAX, desTAX], axis= 1) # 컬럼을 붙이려면 axis=1 컬럼\n",
    "# print(taxCon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533fa2cd",
   "metadata": {},
   "source": [
    "22.6.18.토 p.357"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28b4fc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353    187\n",
      "123    188\n",
      "122    188\n",
      "Name: TAX, dtype: int64\n",
      "492    711\n",
      "491    711\n",
      "490    711\n",
      "Name: TAX, dtype: int64\n",
      "122   NaN\n",
      "123   NaN\n",
      "353   NaN\n",
      "490   NaN\n",
      "491   NaN\n",
      "492   NaN\n",
      "Name: TAX, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# # 헤멤. index 뒤섞인 걸 그대로 하려고 하니까 진전을 못 했다.\n",
    "# import pandas as pd\n",
    "# data= pd.read_csv('bigData/boston.csv')\n",
    "# # help(data) #sort\n",
    "# ascTAX= data['TAX'].sort_values(ascending=True) # df, Series 에 둘다 sort 있는데, 인자 차이뿐.\n",
    "# desTAX= data['TAX'].sort_values(ascending=False)\n",
    "# len(ascTAX)\n",
    "# # 분산 sum(diff^2)\n",
    "# print(ascTAX.iloc[0:3]) # index 353 123 122\n",
    "# print(desTAX.iloc[0:3]) # index 492 491 490\n",
    "\n",
    "# print(ascTAX.iloc[0:3]-desTAX.iloc[0:3]) \n",
    "#>>>>>>> # 전혀 예상밖으로 NAN 6개가 나온다. index 122 123 353 490 491 492\n",
    "# 서로 index 가 다른걸 연산해서."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0616cb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed9ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# data= pd.read_csv('bigData/mtcars.csv')\n",
    "# clip 잘 되는지 확인하고 싶음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73a1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57f4354f",
   "metadata": {},
   "source": [
    "### 2.3 최소최대 변환하기\n",
    "boston 데이터. MEDV 컬럼 MinMaxScaler 변환. 0.5 보다 큰 값을 갖는 레코드 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dceb342",
   "metadata": {},
   "source": [
    "22.6.19.일 16:20 / 권장 ~p.382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ff2cebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data= pd.read_csv('bigData/boston.csv')\n",
    "# import sklearn # help(sklearn) # pacakge. 둘러봄. preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# dir(MinMaxScaler) # fit_transform\n",
    "model= MinMaxScaler()\n",
    "after= model.fit_transform(data[['MEDV']]) # input 2D array\n",
    "# print(len(after)) # 506\n",
    "print(len(after[after >  0.5])) # 106\n",
    "print(type(after[after >  0.5])) # ndarray\n",
    "# ndarray 에는 count 없다. print((after[after >  0.5]).count()) # ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8aa32770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 책: ndarray 를 pd.DataFrame 으로 변경. columns= data.columns 로 컬럼 유지. df.count() 로 셈\n",
    "book= model.fit_transform(data)\n",
    "print(type(book))\n",
    "book= pd.DataFrame(book, columns= data.columns)\n",
    "print(type(book))\n",
    "book.loc[book['MEDV']>0.5, 'MEDV'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79459840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5388bce",
   "metadata": {},
   "source": [
    "### 2.4 빈도값 구하기\n",
    "boston 데이터. AGE 컬럼 소수 첫째 자리에서 반올림. 가장 많은 비중을 차지하는 AGE 값과 그 개수를 차례대로 출력(AGE 최빈값과 그 개수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce2e4c",
   "metadata": {},
   "source": [
    "##### (91,) Series 를 (91,2) DataFrame 으로 변경하는 방법\n",
    "pd.DataFrame(시리즈).reset_index(drop=False, inplace=True)\n",
    "> 새 index 를 만들건데, 기존 index 는 보존하겠다. 어디에? 새 컬럼에! - p.367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3e229e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 43\n"
     ]
    }
   ],
   "source": [
    "# my\n",
    "import pandas as pd\n",
    "data= pd.read_csv('bigData/boston.csv')\n",
    "# help(data['AGE'].round) # decimal param\n",
    "# print(data['AGE'].round(0)) # 0 이 소수 첫째에서. -1 이 일의자리에서, 1이 소수 둘째에서 (0 일의자리로, 1 소수첫째자리로) 반올림\n",
    "# print(data['AGE'].round(0).value_counts())\n",
    "print(data['AGE'].round(0).value_counts().index[0], data['AGE'].round(0).value_counts().iloc[0])\n",
    "# print(data['AGE'].round(0).value_counts().iloc[0]) # 그냥 [0]은 안 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "263d6200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 43\n"
     ]
    }
   ],
   "source": [
    "## 책2- scipy 를 익혀보자\n",
    "# import scipy # help(scipy) # pacakge. stats기초통계 fft io signal신호처리 sparse희소행렬 등\n",
    "# from scipy import stats\n",
    "# dir(stats) # mode, 피어슨, 베이즈, binom, nbinom, boxcox, 카이, 코사인, iqr, mstats, 푸아송, randint\n",
    "# 반원(semicircular), skey, t, uniform, wilcoxon, zscore 등\n",
    "\n",
    "from scipy.stats import mode\n",
    "# help(mode) #(a, axis=0, nan_policy='propagate') #from scipy import stats # stats.mode(a)\n",
    "# 컬럼 다 있는 거 print(data.columns, mode(data))\n",
    "# print(data2.columns, mode(data2)) # data2: 아래칸 먼저 실행. 일의자리까지 반올림하고 'AGE'만 있는 DF.\n",
    "# ModeResult(mode=array([[100.]]), count=array([[43]])) : 최빈값 100. , 개수 43\n",
    "\n",
    "# print(mode(data2)[0][0][0])\n",
    "print(int(mode(data2)[0]), int(mode(data2)[1]))\n",
    "# print(int(mode(data2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "26514b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 43\n",
      "100.0 43\n"
     ]
    }
   ],
   "source": [
    "# 책1- 효율적인 길은 아니지만 복습겸 새 함수 사용법 배울겸\n",
    "data2= round(data['AGE'],0)\n",
    "# print(type(data2)) # Series\n",
    "\n",
    "## groupby 를 써보기 위해 DF 로 변환\n",
    "data2= pd.DataFrame(data2)\n",
    "data3= data2.groupby(['AGE'])['AGE'].count()\n",
    "# print(data2.groupby(['AGE'])['AGE'].count())\n",
    "# type(data2.groupby(['AGE'])['AGE'].count()) #Series\n",
    "# 요상함 print(data2.groupby(['AGE']).count()) # groupby를 대상 컬럼 지정없이 그냥 쓰면 뭔가 생소한 결과가 나온다.\n",
    "# 요상함 type(data2.groupby(['AGE']).count()) # DataFrame. 91 rows 0 columns (???)\n",
    "\n",
    "## index 를 컬럼으로 바꾸기 위해 DataFrame 으로 전환\n",
    "data3= pd.DataFrame(data3)\n",
    "data3.columns= ['COUNT']\n",
    "# print(data3.tail(2)) # AGE 가 index, COUNT 가 컬럼\n",
    "# print(type(data3), data3.shape) # DataFrame (91,1)\n",
    "\n",
    "data3.reset_index(drop=False, inplace=True)\n",
    "# print(data3.tail(2))\n",
    "# print(type(data3), data3.shape) # DataFrame (91,2) <<<<<< !!!\n",
    "# print(data3.iloc[-1])\n",
    "print(data3.iloc[-1,0], data3.iloc[-1,1]) # 이러면 끝이지만\n",
    "\n",
    "## sort_values 를 써보기 위해\n",
    "data3.sort_values(by= 'COUNT', ascending=False, inplace=True)\n",
    "# print(data3.head(3))\n",
    "print(data3.iloc[0,0], data3.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65656091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30a6f103",
   "metadata": {},
   "source": [
    "### 2.5 표준 변환하기\n",
    "boston 데이터. DIS 컬럼을 표준화척도(Standard Scale)로 변환 후, 0.4보다 크면서 0.6보다 작은 값들에 대해 평균 구하기. 소수 셋째자리에서 반올림하여 소수 둘째자리까지 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c3b4f777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> [[0.1402136 ]\n",
      " [0.55715988]\n",
      " [0.55715988]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data= pd.read_csv('bigData/boston.csv')\n",
    "# data.columns\n",
    "# from sklearn import preprocessing # dir(preprocessing)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler= StandardScaler()\n",
    "dataDIS= scaler.fit_transform(data[['DIS']])\n",
    "print(type(dataDIS), dataDIS[0:3]) # ndarray\n",
    "# 틀림. 값이 중복으로 더 들어가더니 고장난다. -8.4e-17. dataDIS[(dataDIS > 0.4) | (dataDIS < 0.6)].mean()\n",
    "dataDIS[(dataDIS > 0.4) & (dataDIS < 0.6)].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846749e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5381a7ec",
   "metadata": {},
   "source": [
    "### 2.6 유니크한 값 구하기\n",
    "boston 데이터. 중복제거. 컬럼 별로 유니크한 값의 개수를 기준으로 평균값을 구하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6164b008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data= pd.read_csv('bigData/boston.csv')\n",
    "print(data.nunique().mean()) # 0행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "24ac25bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218.07142857142858\n",
      "3053 14\n",
      "3052\n",
      "434\n",
      "0    433\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## nunique() 를 모른다고 할 때\n",
    "# help(data.apply)\n",
    "# print(data.dtypes) # float64 or int64\n",
    "# print(data.info()) # 'RM' 에만 null 이 있다.\n",
    "# data.applymap(lambda x: pd.unique(x))  #'float' object is not iterable\n",
    "\n",
    "# data[['CRIM','ZN','INDUS']].applymap(lambda x: pd.unique(x))\n",
    "# 이 시도가 잘못된 이유: 개별 요소마다 unique() 를 적용하려고 하는데, unique(32.5) 하면 당연히 에러!\n",
    "\n",
    "# 원래 의도: 개별 요소가 아니라 각 열마다 unique() 적용\n",
    "# data.unique(axis=1) # DF 에 unique 없다\n",
    "\n",
    "cols= data.columns\n",
    "uniqueSum= 0\n",
    "# print(len(data['CRIM'].unique()))\n",
    "# print(len(data['CRIM']))\n",
    "for col in cols:\n",
    "#     print(data[col].unique().count())\n",
    "    uniqueSum+= len(data[col].unique())\n",
    "print(uniqueSum/len(cols))\n",
    "print(uniqueSum, len(cols))\n",
    "print(218 *14)\n",
    "\n",
    "# print(data.info()) # 'RM' 에만 null 이 있다.\n",
    "print(len(data['RM'].unique()))\n",
    "print(pd.DataFrame(data['RM'].unique()).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d91e7fd",
   "metadata": {},
   "source": [
    "[dataframe apply unique](https://stackoverflow.com/a/48409827)\n",
    "df.apply(lambda x: pd.unique(x).tolist())\n",
    "- unique() 는 전역함수가 아니기에, 그냥 쓰면 \"name 'unique' is not defined\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690d6c0",
   "metadata": {},
   "source": [
    "[applymap 'float' object is not iterable](https://stackoverflow.com/a/58742977)\n",
    "- null 이 있으면 적용이 안 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdfbf13",
   "metadata": {},
   "source": [
    "##### [공식  applymap](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.applymap.html)\n",
    "\n",
    "\n",
    "##### [map, apply, applymap](http://www.leejungmin.org/post/2018/04/21/pandas_apply_and_map/)\n",
    "예제가 어렵. 공식을 보자\n",
    "- map: Series 에만. df['winning_rate']  = df['team'].map(lambda x : 커스텀함수return(x)). 요소하나하나에 적용. 함수뿐 아니라 딕셔너리 및 Series 도 가능\n",
    "- apply: DF, Series 둘다. \n",
    "- applymap: DF. 각 요소에 적용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "63e4ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb\n",
    "# a= 5\n",
    "# pdb.set_trace() \n",
    "# b 숫자. 브레이크포인트 대상함수에다가 # c continue 다음 브레이크까지 # n next # 변수명 값보기\n",
    "# print(5, \"이게 뭐지. python debugger\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
