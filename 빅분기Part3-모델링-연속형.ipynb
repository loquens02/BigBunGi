{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5340e435",
   "metadata": {},
   "source": [
    "# 빅분기Part3-모델링-예측(연속형)\n",
    "Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980dd9de",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81436e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cyl      disp        hp      drat vs  gear  carb am_manual wt_class  \\\n",
      "0   0.20  0.257286  0.229023  0.689171  0     4     4         1        0   \n",
      "1   0.20  0.257286  0.229023  0.689171  0     4     4         1        0   \n",
      "2   0.00  0.106792  0.161895  0.658000  1     4     1         1        0   \n",
      "3   0.20  0.540908  0.229023  0.177961  1     3     1         0        0   \n",
      "4   0.40  0.836107  0.485686  0.221601  0     3     2         0        1   \n",
      "5   0.20  0.445403  0.209279  0.000000  1     3     1         0        1   \n",
      "6   0.40  0.836107  0.762093  0.259006  0     3     4         0        1   \n",
      "7   0.36  0.218794  0.039487  0.558251  1     4     2         0        0   \n",
      "8   0.00  0.201719  0.169793  0.701640  1     4     2         0        0   \n",
      "9   0.20  0.279281  0.280355  0.701640  1     4     4         0        1   \n",
      "10  0.20  0.279281  0.280355  0.701640  1     4     4         0        1   \n",
      "11  0.40  0.592423  0.505429  0.171727  0     3     3         0        1   \n",
      "12  0.40  0.592423  0.505429  0.171727  0     3     3         0        1   \n",
      "13  0.40  0.592423  0.505429  0.171727  0     3     3         0        1   \n",
      "14  1.00  1.000000  0.604146  0.084447  0     3     4         0        1   \n",
      "15  0.40  1.000000  0.643633  0.128087  0     3     4         0        1   \n",
      "16  0.40  1.000000  0.702863  0.271475  0     3     4         0        1   \n",
      "17  0.00  0.021995  0.055281  0.801388  1     4     1         1        0   \n",
      "18  0.00  0.013313  0.000000  1.000000  1     4     2         1        0   \n",
      "19  0.00  0.000000  0.051333  0.888668  1     4     1         1        0   \n",
      "20  0.00  0.141811  0.177690  0.564486  1     3     1         0        0   \n",
      "21  0.40  0.714555  0.386969  0.000000  0     3     2         0        1   \n",
      "22  0.40  0.674037  0.386969  0.221601  0     3     2         0        1   \n",
      "23  0.40  0.807166  0.762093  0.583189  0     3     4         0        1   \n",
      "24  0.36  0.951871  0.485686  0.177961  0     3     2         0        1   \n",
      "25  0.00  0.022863  0.055281  0.801388  1     4     1         1        0   \n",
      "26  0.00  0.142390  0.153998  1.000000  0     5     2         1        0   \n",
      "27  0.00  0.069459  0.240869  0.608126  1     5     2         1        0   \n",
      "28  0.40  0.810060  0.837117  0.888668  0     5     4         1        0   \n",
      "29  0.20  0.213874  0.485686  0.514612  0     5     6         1        0   \n",
      "30  0.40  0.665355  1.000000  0.464737  0     5     7         1        1   \n",
      "31  0.00  0.144416  0.225074  0.820091  1     4     2         1        0   \n",
      "\n",
      "      qsec_4  \n",
      "0   0.352968  \n",
      "1   0.421512  \n",
      "2   0.616126  \n",
      "3   0.000000  \n",
      "4   0.421512  \n",
      "5   0.813188  \n",
      "6   0.277081  \n",
      "7   0.786261  \n",
      "8   1.000000  \n",
      "9   0.578182  \n",
      "10  0.000000  \n",
      "11  0.468023  \n",
      "12  0.492503  \n",
      "13  0.541463  \n",
      "14  0.539015  \n",
      "15  0.519431  \n",
      "16  0.470471  \n",
      "17  0.721389  \n",
      "18  0.605110  \n",
      "19  0.774021  \n",
      "20  0.787485  \n",
      "21  0.403152  \n",
      "22  0.455783  \n",
      "23  0.224449  \n",
      "24  1.000000  \n",
      "25  0.651622  \n",
      "26  0.382344  \n",
      "27  0.406824  \n",
      "28  0.113066  \n",
      "29  0.235465  \n",
      "30  0.125306  \n",
      "31  0.614902   -----\n",
      "실행시간: 12.42488 sec\n"
     ]
    }
   ],
   "source": [
    "### 시간 측정, 데이터 로드, 종속-독립변수 분리\n",
    "import pandas as pd\n",
    "import time\n",
    "start_time= time.time()\n",
    "data=pd.read_csv('bigData/mtcars.csv')\n",
    "# print(data.info(), data.head(),'-----'))\n",
    "Y= data['mpg']\n",
    "X= data.drop(columns=['mpg','Unnamed: 0'])\n",
    "pd.set_option('display.max_columns',None) # s!\n",
    "X.head()\n",
    "\n",
    "### null 찾고 채우기, 이상한 값 찾고 바꾸기, 이상한 타입 바꾸기, 인코딩\n",
    "# print(X.loc[X.isnull().sum(1) != 0], '-----'))\n",
    "X['cyl'].fillna(X.describe().loc['mean','cyl'], inplace=True)\n",
    "X['qsec'].fillna(X.describe().loc['mean','cyl'], inplace=True)\n",
    "# print(X, '-----'))\n",
    "# print(X.loc[:,X.dtypes==object].iloc[:,1].unique(), '-----')) #'gear'\n",
    "# print(X.info(), '-----')) \n",
    "X['gear']= X['gear'].replace('*3','3').replace('*5','5').astype('int64') # min 이상치에 'gear' 도 포함된다\n",
    "# print(pd.get_dummies(X, drop_first=True), '-----')) # help(pd.get_dummies)\n",
    "# print(X['am'].unique(), '-----'))\n",
    "# print(X, '-----'))\n",
    "X= pd.get_dummies(X, drop_first=True)\n",
    "# print(X, '-----')) # am_auto 뿐만 아니라, 기존 am 컬럼도 자동으로 지워진다.\n",
    "# print(X.info(), '-----'))\n",
    "\n",
    "### 이상치 교체(meanStd or IQR)\n",
    "## describe -> mean +- 1.5*std , Q3 + 1.5*IQR 및 Q1 - 1.5*IQR -> def 컬럼 별. maxOver minOver. 찾는 것부터\n",
    "# True 중에 중복 처리없게 골라내기. int64는 되도록 유지하기\n",
    "# print(X.loc[:,X.dtypes=='int64'].nunique(), '-----')) # hp22, vs2, gear3, carb6 종\n",
    "# print(X.loc[:,X.dtypes=='int64'], '-----')) # vs 01, gear 345, carb 123468 \n",
    "# 컬럼 조건만 알아본 것\n",
    "def outlierCheck(data):\n",
    "    desc= data.describe()\n",
    "    max1= desc.loc['max']\n",
    "    min1= desc.loc['min']\n",
    "    \n",
    "    mean= desc.loc['mean']\n",
    "    std= desc.loc['std']\n",
    "    minBms= mean - 1.5*std\n",
    "    maxBms= mean + 1.5*std\n",
    "    minOverMs= min1 < minBms # Boundary 보다 작으면 이상치\n",
    "    maxOverMs= max1 > maxBms # Boundary 보다 크면 이상치\n",
    "#     print(minOverMs, '-----')) # drat, wt 만\n",
    "#     print(maxOverMs, '-----')) # vs, am_maunal 빼고 다 => disp, drat 만. gear 제외\n",
    "    \n",
    "    Q1= desc.loc['25%']\n",
    "    Q3= desc.loc['75%']\n",
    "    IQR= Q3-Q1\n",
    "    minBiqr= Q1 - 1.5*IQR\n",
    "    maxBiqr= Q3 + 1.5*IQR\n",
    "    minOverIQR= min1 < minBiqr\n",
    "    maxOverIQR= max1 > maxBiqr\n",
    "#     print(minOverIQR, '-----')) # qsec 만\n",
    "#     print(maxOverIQR, '-----')) # cyl, hp, wt, qsec, carb => carb 유지. 기화기는 엔진 부품. 8개면 좀 이상하긴하다\n",
    "    \n",
    "    #     print(minBms, maxBms, minBiqr, maxBiqr, '-----'))\n",
    "    return minBms, maxBms, minBiqr, maxBiqr\n",
    "\n",
    "# outlierCheck(X)\n",
    "\n",
    "# 뭘 바꿀지 이미 정했으므로 행 조건만 알면 된다.\n",
    "def outlierReplace(data):\n",
    "    minBms, maxBms, minBiqr, maxBiqr= outlierCheck(data)\n",
    "    #행 조건- 각 열 내의 값이 Boundary Over 인지. data[col]<minBms[col]\n",
    "    #열 조건\n",
    "    minMScols= ['drat','wt']\n",
    "    maxMScols= ['disp','drat']\n",
    "    minIQRcols= ['qsec']\n",
    "    maxIQRcols= ['cyl', 'hp', 'wt', 'qsec', 'carb']\n",
    "    \n",
    "    #     print(type(minBms), '-----'))\n",
    "    #     print(minBms[column], '-----'))\n",
    "    for col in minMScols:\n",
    "#         print(f\"BeforeMinMS: {data.loc[ data[col]<minBms[col],col]}, minBms: {minBms[col]:.7}\") \n",
    "        data.loc[ data[col]<minBms[col], col]= minBms[col]\n",
    "    for col in maxMScols:\n",
    "#         print(f\"BeforeMaxMS: {data.loc[ data[col]>maxBms[col],col]}, maxBms: {maxBms[col]:.7}\")\n",
    "        data.loc[ data[col]>maxBms[col], col]= maxBms[col]\n",
    "    for col in minIQRcols:\n",
    "#         print(f\"BeforeMinIQR: {data.loc[ data[col]<minBiqr[col],col]}, minBiqr: {minBiqr[col]:.7}\")\n",
    "        data.loc[ data[col]<minBiqr[col], col]= minBiqr[col]\n",
    "    for col in maxIQRcols:\n",
    "#         print(f\"BeforeMaxIQR: {data.loc[ data[col]>maxBiqr[col],col]}, maxBiqr: {maxBiqr[col]:.7}\")\n",
    "        data.loc[ data[col]>maxBiqr[col], col]= maxBiqr[col]\n",
    "    return data\n",
    "\n",
    "X= outlierReplace(X) # inplace 될 때도 있고, 안 될 때도 있어서 확실히 해두기.\n",
    "# print(f\"로드~이상치 처리 시간: {time.time()-start_time:.7} sec\") #  0.095 sec\n",
    "# print(X, '-----'))\n",
    "\n",
    "### 범위 맞추기\n",
    "# from sklearn import preprocessing\n",
    "# help(preprocessing)\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, LabelEncoder\n",
    "# print(X.describe(), '-----'))\n",
    "def rangeScaler(scalers, columnDataFrame): # 이 인자 외워야. X[[ ]]\n",
    "    if scalers=='MinMax':\n",
    "        scaler= MinMaxScaler()\n",
    "    elif scalers=='Standard':\n",
    "        scaler= StandardScaler()\n",
    "    elif scalers=='Robust':\n",
    "        scaler= RobustScaler()\n",
    "    #     help(scaler.fit_transform)\n",
    "    scaledDf= pd.DataFrame(scaler.fit_transform(columnDataFrame)) # 이 형태 외워야.\n",
    "    return scaledDf\n",
    "\n",
    "# print(X[['qsec']], '-----'))\n",
    "# ret2= rangeScaler('MinMax', X[['qsec']]) # min 0, max 1\n",
    "# ret2= rangeScaler('Standard', X[['qsec']]) # mean 0 근접, std 1 근접\n",
    "# ret2= rangeScaler('Robust', X[['qsec']]) # mid 0, IQR= Q3-Q1= 1\n",
    "# print(ret2.describe(), '-----'))\n",
    "# print(ret2.describe().loc['75%']-ret2.describe().loc['25%'])\n",
    "# print(ret2, '-----'))\n",
    "\n",
    "## 범주형 명시- category\n",
    "# help(X['am_manual'].astype) #Convert to categorical type\n",
    "X['am_manual']= X['am_manual'].astype('category')\n",
    "X['vs']= X['vs'].astype('category')\n",
    "# print(X.info(), '-----'))\n",
    "\n",
    "## LabelEncoder 연습\n",
    "# face= ['happy','sad','soso']\n",
    "# from sklearn import preprocessing\n",
    "# help(preprocessing)\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# encoder= LabelEncoder()\n",
    "# print(face, encoder.fit_transform(face), '-----'))\n",
    "\n",
    "### 파생변수\n",
    "## 무게등급\n",
    "condition= X['wt'] < 3.3\n",
    "X.loc[condition, 'wt_class']= 0 # 작\n",
    "X.loc[~condition, 'wt_class']= 1 #크거나 같\n",
    "X.drop(columns='wt',inplace=True)\n",
    "# print(X, '-----')\n",
    "X['wt_class']= X['wt_class'].astype('int64').astype('category') # float 에 category 는 deprecated\n",
    "# print(X, '-----')\n",
    "## 1mile\n",
    "X['qsec_4']= X['qsec']*4\n",
    "# print(X[['qsec_4','qsec']], '-----')\n",
    "X.drop(columns='qsec', inplace=True)\n",
    "# print(X, '-----')\n",
    "\n",
    "### 표준화 적용- 파생변수 뒤에 와야\n",
    "targetCols= X.columns[(X.dtypes=='float64')]\n",
    "for col in targetCols:\n",
    "    X[col]= rangeScaler('MinMax', X[[col]]) # MinMax 종속 연속형\n",
    "\n",
    "print(X, '-----')\n",
    "print(f\"실행시간: {time.time()-start_time:.7} sec\") # 0.130 sec (6.858 sec 는 최초 module 로드탓)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f8e41",
   "metadata": {},
   "source": [
    "## 모델링\n",
    "p.280"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15a7fa",
   "metadata": {},
   "source": [
    "### 1. 학습용과 검증용 데이터 나누기\n",
    "- 입력: 독립변수, 종속변수, 검증 데이터 비율\n",
    "- 나누지 않으면 주어진 데이터에 과적합되어 새 데이터는 못 맞추는 일이 발생할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0291924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 10)     cyl      disp        hp      drat vs  gear  carb am_manual wt_class  \\\n",
      "19  0.0  0.000000  0.051333  0.888668  1     4     1         1        0   \n",
      "14  1.0  1.000000  0.604146  0.084447  0     3     4         0        1   \n",
      "18  0.0  0.013313  0.000000  1.000000  1     4     2         1        0   \n",
      "6   0.4  0.836107  0.762093  0.259006  0     3     4         0        1   \n",
      "11  0.4  0.592423  0.505429  0.171727  0     3     3         0        1   \n",
      "\n",
      "      qsec_4  \n",
      "19  0.774021  \n",
      "14  0.539015  \n",
      "18  0.605110  \n",
      "6   0.277081  \n",
      "11  0.468023  \n",
      "(10, 10)      cyl      disp        hp      drat vs  gear  carb am_manual wt_class  \\\n",
      "20  0.00  0.141811  0.177690  0.564486  1     3     1         0        0   \n",
      "7   0.36  0.218794  0.039487  0.558251  1     4     2         0        0   \n",
      "5   0.20  0.445403  0.209279  0.000000  1     3     1         0        1   \n",
      "2   0.00  0.106792  0.161895  0.658000  1     4     1         1        0   \n",
      "3   0.20  0.540908  0.229023  0.177961  1     3     1         0        0   \n",
      "\n",
      "      qsec_4  \n",
      "20  0.787485  \n",
      "7   0.786261  \n",
      "5   0.813188  \n",
      "2   0.616126  \n",
      "3   0.000000  \n",
      "(22,) 19    33.9\n",
      "14    10.4\n",
      "18    30.4\n",
      "6     14.3\n",
      "11    16.4\n",
      "Name: mpg, dtype: float64\n",
      "(10,) 20    21.5\n",
      "7     24.4\n",
      "5     18.1\n",
      "2     22.8\n",
      "3     21.4\n",
      "Name: mpg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# import sklearn\n",
    "# help(sklearn) # package/ model_selection\n",
    "# from sklearn import model_selection\n",
    "# help(model_selection) #train_test_split . 적어도 train_ 은 알고있어야\n",
    "from sklearn.model_selection import train_test_split\n",
    "# help(train_test_split) # examples\n",
    "# 인자: 독립변수X set, 종속변수Y set, test 비율, [random_state]\n",
    "# 반환: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, Y, test_size=0.3, random_state=10) \n",
    "# random_state 동일결과 확인용. 시험때는 안 넣어도 된다.\n",
    "print(X_train.shape, X_train.head())\n",
    "print(X_test.shape, X_test.head())\n",
    "print(y_train.shape, y_train.head())\n",
    "print(y_test.shape, y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cc8d8e",
   "metadata": {},
   "source": [
    "### 2-1. 모델 학습- 선형회귀 모델로 - LinearRegression\n",
    "p.287 / 얘는 끝이 ssion 인데, 랜포는 끝이 ssor 다. 주의!\n",
    "1. from sklearn.모듈 import 모델함수\n",
    "> 사용할 모델의 함수 가져오기 / 모듈: linear_model, \n",
    "2. model= 모델함수()\n",
    "> 학습 모델 만들기\n",
    "3. model.fit(X_train, y_train)\n",
    "> 학습 데이터로 모델 학습시키기\n",
    "4. y_train 예측값= model.predict(X_train); y_test 예측값= model.predict(y_test)\n",
    "> 학습된 모델로 값 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f859a723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.56286898 10.79692316 28.08087817 12.90630892 16.70637907 12.9147253\n",
      " 18.25719718 15.6210032  17.95764897 17.70480304 28.52209218 27.42093781\n",
      " 23.4210032  27.37933004 12.53871217 30.02303612 30.25771369 20.98703828\n",
      " 12.67073112 16.91890106 18.64510153 19.60666681]\n",
      "[23.57060281 21.40453648 23.48566784 29.44648854 17.96796599 17.53658796\n",
      " 16.94794949 17.85706881 16.78690255 21.212504  ]\n"
     ]
    }
   ],
   "source": [
    "# import sklearn\n",
    "# help(sklearn) # package/ linear_model\n",
    "# from sklearn import linear_model\n",
    "# help(linear_model) # classes 6째 단락에 있긴한데 잘 안 보임. LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# help(LinearRegression) #reg = LinearRegression().fit(X, y) #reg.score(X, y), reg.coef_ , reg_intercept_ #reg.predict()\n",
    "\n",
    "# 학습할 학생= 모델\n",
    "model= LinearRegression() \n",
    "# 학생에게 문제집 풀게하기= 학습\n",
    "model.fit(X_train, y_train)\n",
    "# 학생 시험치기- 문제집에 있는 문제로= 예측\n",
    "y_train_predict= model.predict(X_train)\n",
    "print(y_train_predict) # 예측값\n",
    "\n",
    "# X_train 으로 만든걸 y_train_predict 라 이름 붙인다. > score 낼 때 헷갈리는데, 여하튼 predict 결과로 보고 싶은건 y 종속변수라 그렇다\n",
    "\n",
    "# 학생 시험치기- 문제집에 없는 문제로= 예측\n",
    "y_test_predict= model.predict(X_test)\n",
    "print(y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf2f68",
   "metadata": {},
   "source": [
    "plot 은 그릴 수 없지만, 선형회귀식 => 선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9656c94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y절편: 18.95377826275987\n",
      "Index(['cyl', 'disp', 'hp', 'drat', 'vs', 'gear', 'carb', 'am_manual',\n",
      "       'wt_class', 'qsec_4'],\n",
      "      dtype='object')\n",
      "각 독립변수의 기울기: [-3.20044458 -5.97268067  0.42522434  0.0267941   0.60020276  1.33687083\n",
      " -1.82802038  4.89773449  2.28555265  3.28938387]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y절편: {model.intercept_}\")\n",
    "print(X.columns)\n",
    "print(f\"각 독립변수의 기울기: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce72f46",
   "metadata": {},
   "source": [
    "##### 모델 평가 \n",
    "예측한 값이 믿을 수 있는지\n",
    "1. from sklearn.metrics import 평가함수\n",
    "> 평가할 함수 가져오기\n",
    "2. print(평가함수(y_train, y_train의 예측값); print(평가함수(y_test, y_test의 예측값)\n",
    "> 모델 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2180f952",
   "metadata": {},
   "source": [
    "p.288\n",
    "- model.score(). 결정계수. 실제분산과 예측분산의 비율이 1에 가까울수록 정확도가 높음. r2_score() 와 같음\n",
    "\n",
    "##### 이건 predict 수행여부와는 별개더라\n",
    "왜지. 이미 한 번 실행해서 먹히는 것일듯?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f749b3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.90556938821305\n",
      "test: -0.10693839514421422\n"
     ]
    }
   ],
   "source": [
    "# help(model.score) #score(X, y, sample_weight=None) : R^2\n",
    "# 문제집에 있는 문제 기준으로 학생의 공부결과 평가\n",
    "print(f\"train: {model.score(X_train, y_train)}\")\n",
    "# 문제집에 없는 새로운 문제로 학생의 공부결과 평가\n",
    "print(f\"test: {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a859d",
   "metadata": {},
   "source": [
    "종속변수 실제값과 종속변수 예측값 간의 이러저런 차이 > y 랑 y_predict 간 차이\n",
    "- MAE. mean_absolute_error. mean(|실제값-예측값|)\n",
    "- MSE. mean_squared_error. mean(|실제값-예측값|^2)\n",
    "- RMSE. root MSE. sqrt(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a9d409ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분산 비율 > 1에 가까울수록 좋다\n",
      "R^2 train:  0.9999999861571242\n",
      "R^2 test:  0.2905203422802105\n",
      "\n",
      "차이 > 0에 가까울수록 좋다\n",
      "MAE test:  2.209756946563721\n",
      "MSE test:  7.047970919788388\n",
      "RMSE test:  2.6548014840639946\n"
     ]
    }
   ],
   "source": [
    "# import sklearn # help(sklearn) # metrics\n",
    "# from sklearn import metrics #help(metrics) # 한 중간에 있어서 보기어렵. mean_a mean_s r2_검색. \n",
    "# r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "#제곱근 계산\n",
    "import numpy as np\n",
    "# help(np) # np.sqrt\n",
    "\n",
    "print('분산 비율 > 1에 가까울수록 좋다') \n",
    "print('R^2 train: ',r2_score(y_train, y_train_predict)) \n",
    "print('R^2 test: ',r2_score(y_test, y_test_predict))\n",
    "\n",
    "print('\\n차이 > 0에 가까울수록 좋다')\n",
    "# print('MAE train: ',mean_absolute_error(y_train, y_train_predict))\n",
    "print('MAE test: ',mean_absolute_error(y_test, y_test_predict))  # 종속변수 실제값과 종속변수 예측값 간의 이러저런 차이\n",
    "\n",
    "# 차이 > 0에 가까울수록 좋다\n",
    "# MSEtrain=mean_squared_error(y_train, y_train_predict)\n",
    "MSEtest= mean_squared_error(y_test, y_test_predict)\n",
    "# print('MSE train: ',MSEtrain)\n",
    "print('MSE test: ',MSEtest)\n",
    "\n",
    "# 차이 > 0에 가까울수록 좋다\n",
    "# print('RMSE train: ',np.sqrt(MSEtrain))\n",
    "print('RMSE test: ',np.sqrt(MSEtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa206ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f6ca04f",
   "metadata": {},
   "source": [
    "### 2-2. 모델학습 및 평가- 랜덤 포레스트 회귀분석\n",
    "p.290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e216e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn # help(sklearn) #ensemble. 앙상블. 이건 외우고 있어야.\n",
    "# from sklearn import ensemble # help(ensemble) #randomforest/ RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42c4ec",
   "metadata": {},
   "source": [
    "'22.6.16.목 23:17 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26ac602",
   "metadata": {},
   "source": [
    "'22.6.17.금 12:15\n",
    "~297 ~321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a532715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f97ce8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cyl', 'disp', 'hp', 'drat', 'vs', 'gear', 'carb', 'am_manual',\n",
      "       'wt_class', 'qsec_4'],\n",
      "      dtype='object')\n",
      "[32.826 10.952 30.066 14.344 16.196 13.891 18.061 14.716 16.147 18.19\n",
      " 28.169 23.35  23.034 24.944 14.352 28.839 31.605 20.823 11.15  17.375\n",
      " 19.915 18.844]\n",
      "[26.343 22.112 18.883 28.037 19.774 15.737 15.089 14.673 16.1   20.823]\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)\n",
    "# 학습자(모델) 생성\n",
    "model= RandomForestRegressor(random_state=10)\n",
    "# 학습자에게 문제집70% 제공해서 학습하도록\n",
    "model.fit(X_train, y_train) # y는 Series 이어야 한다. df ㄴㄴ\n",
    "# 학습자에게 문제70% 중 아무거나 줘서 잘 학습했는지 확인\n",
    "y_train_predict= model.predict(X_train)\n",
    "print(y_train_predict)\n",
    "# 학습자에게 나머지 문제 30% 중 아무거나 줘서 학습한 거 외에도 잘 푸는 지 확인\n",
    "y_test_predict= model.predict(X_test)\n",
    "print(y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8edb3fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.9803626391120417\n",
      "test:  0.3740419267163213\n",
      "test:  1.7629000000000055\n",
      "test:  6.218267500000064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 학습문제70% 로 보는 점수. 주어진 문제 잘 공부했는지. 이게 낮으면 아직 덜 공부한 것.\n",
    "print('train: ',r2_score(y_train, y_train_predict)) \n",
    "\n",
    "# R^2. 결정계수. 종속변수 실제값과 예측값 비율. 1에 가까울 수록 정확\n",
    "print('test: ',r2_score(y_test, y_test_predict)) # 나머지 문제 30%로 보는 점수. 모델 실전 평가\n",
    "\n",
    "# MAE. 종속변수 |실제값과 예측값 차이|\n",
    "print('test: ',mean_absolute_error(y_test, y_test_predict))\n",
    "\n",
    "# MSE. 종속변수 |실제값과 예측값 차이|^2\n",
    "print('test: ',mean_squared_error(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd339c71",
   "metadata": {},
   "source": [
    "시험에 R2, MAE, MSE, RMSE 중 뭐로 평가하라고 할지 모른다.\n",
    "- 안 정해주면 score 높은 (R2 면 1에 가깝고, 나머지는 0에 가까운) 것 골라서 넣고\n",
    "- 정해준다면 모델을 조정하여 점수를 높이자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f9e48",
   "metadata": {},
   "source": [
    "####  하이퍼 파라미터\n",
    "모델을 조정하는 방법 / p.292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8fdbb16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(RandomForestRegressor)\n",
    "# (n_estimators=100, *, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0\n",
    "# ,max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None\n",
    "# , bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e315048b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train:  0.9809794570146911\n",
      "R2 test:  0.45810313267565417\n",
      "MAE test:  1.7127200000000264\n",
      "MSE test:  5.383203480000051\n",
      "RMSE test:  2.3201731573311615\n",
      "랜포 실행시간 1.788558 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "start_time= time.time()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# 투표할 트리 1천개, 트리 분할기준은 MAE\n",
    "# model= RandomForestRegressor(n_estimators=1000, criterion='mae', random_state= 10)\n",
    "model= RandomForestRegressor(n_estimators=1000, criterion='mse', random_state= 10)\n",
    "\n",
    "# 모델 학습(70%)\n",
    "model.fit(X_train, y_train)\n",
    "# 모델 예측(70%. 시험범위)\n",
    "y_train_predict= model.predict(X_train)\n",
    "# 모델 예측(나머지 30%. 범위 밖)\n",
    "y_test_predict= model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "# 모델 평가(70%. 시험범위)\n",
    "print('R2 train: ',r2_score(y_train, y_train_predict))\n",
    "# 모델 평가(나머지 30%)- R2\n",
    "print('R2 test: ',r2_score(y_test, y_test_predict))\n",
    "# 모델 평가(나머지 30%)- MAE\n",
    "print('MAE test: ',mean_absolute_error(y_test, y_test_predict))\n",
    "# 모델 평가(나머지 30%)- MSE\n",
    "print('MSE test: ',mean_squared_error(y_test, y_test_predict))\n",
    "# 모델 평가(나머지 30%)- RMSE\n",
    "print('RMSE test: ', np.sqrt(mean_squared_error(y_test, y_test_predict)))\n",
    "#\n",
    "print(f\"랜포 실행시간 {time.time()-start_time:.7} sec\") #0.9798 ~1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab2241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d40e973",
   "metadata": {},
   "source": [
    "### 2-3. 모델학습 및 평가- 그래디언트 부스팅 회귀\n",
    "GradientBoostingRegressor. p.293\n",
    "- decision tree 묶기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cadc5c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import ensemble # help(ensemble) # regressor 검색. GradientBoostingRegressor\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# help(GradientBoostingRegressor) \n",
    "#(*, loss='ls', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse'\n",
    "# , min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0\n",
    "# , min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None\n",
    "# , warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0972c699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train기본:  0.9999940057279647\n",
      "R2 train r2_:  0.9999940057279647\n",
      "R2 test:  0.2191733401187025\n",
      "MAE test:  2.007699537572006\n",
      "MSE test:  7.756732039260808\n",
      "그래디언트부스팅 수행시간: 0.08700275 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time= time.time()\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# 학습자. 70% 학습, 70% 예측, 나머지 30% 예측\n",
    "model= GradientBoostingRegressor(random_state=10)\n",
    "model.fit(X_train, y_train)\n",
    "y_train_predict= model.predict(X_train) # 결과가 y라서\n",
    "y_test_predict= model.predict(X_test)\n",
    "\n",
    "# Train 평가, test 평가[R2, MAE, MSE]\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "print(\"R2 train기본: \",model.score(X_train, y_train)) # <=> r2_score(y_train, model.fit(X_train, y_train) )\n",
    "print(\"R2 test: \",r2_score(y_test, y_test_predict)) # <=> model.score(X_test, y_test)\n",
    "print(\"MAE test: \",mean_absolute_error(y_test, y_test_predict))\n",
    "print(\"MSE test: \",mean_squared_error(y_test, y_test_predict))\n",
    "print(f\"그래디언트부스팅 수행시간: {time.time()-start_time:.7} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a073cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63d93f34",
   "metadata": {},
   "source": [
    "### 2-4. 모델학습 및 평가 - 익스트림 그래디언트 부스팅\n",
    "XGB Regressor. 흔히 말하는 xgboost. 성능 끝판왕이지만 시험때는 자제\n",
    "- 다수의 성능 떨어지는 분류기를 합쳤더니 성능이 좋아지더라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d40d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost # Anaconda 기본에도 미설치인데 시험장에 설치가 되어있을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a23cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost # help(xgboost) #class/ XGBRegressor, XGBClassifier. 특이한 게 package에 sklearn 이 있다\n",
    "# from xgboost import XGBRegressor\n",
    "# help(XGBRegressor) \n",
    "# (XGBModel, sklearn.base.RegressorMixin)  |  XGBRegressor(*\n",
    "#, objective: Union[str, Callable[[numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] \n",
    "#= 'reg:squarederror', **kwargs: Any) -> None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1845ff",
   "metadata": {},
   "source": [
    "이걸로 안 됨 [xgboost DMatrix parameter `enable_categorical` must be set to `True`.](https://velog.io/@gibonki77/EX6-ray-tune-%EC%9C%BC%EB%A1%9C-XGBoost-%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0-%ED%8A%9C%EB%8B%9D%ED%95%98%EA%B8%B0)\n",
    "- model.fit() 에 넣는 설명이 없는데, 시험장에서는 category 없애는 방법으로 해야지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a88ffb4",
   "metadata": {},
   "source": [
    "[깊은 복사](https://wikidocs.net/16038) 원본 영향 없이 전체 복사\n",
    "- import copy\n",
    "- b = copy.deepcopy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1203f584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['vs', 'am_manual', 'wt_class'], dtype='object')\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns[X.dtypes=='category'])\n",
    "import copy\n",
    "X_xgb= copy.deepcopy(X)\n",
    "X_xgb['vs']= X_xgb['vs'].astype('int64')\n",
    "X_xgb['am_manual']= X_xgb['am_manual'].astype('int64')\n",
    "X_xgb['wt_class']= X_xgb['wt_class'].astype('int64')\n",
    "print(X_xgb.columns[X_xgb.dtypes=='category'])\n",
    "\n",
    "\n",
    "# import sklearn # help(sklearn) #model_selection\n",
    "# from sklearn import model_selection # help(model_selection) # see also/ train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# help(train_test_split) # example/ X_train, X_test, y_train, y_test= train_test_split(\n",
    "#    ...     X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "xgboost_X_train, xgboost_X_test, xgboost_y_train, xgboost_y_test= train_test_split(\\\n",
    "X_xgb, Y, test_size= 0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "34cb32a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R2:  0.9999999861571242\n",
      "test R2:  0.2905203422802105\n",
      "test MAE:  2.209756946563721\n",
      "test MSE:  7.047970919788388\n",
      "XGB Regressor 수행시간: 0.1259995 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time= time.time()\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "# 학습자. 70% 학습, 70%에서 예측. 나머지 30%에서 예측\n",
    "model= XGBRegressor()\n",
    "\n",
    "model.fit(xgboost_X_train, xgboost_y_train)\n",
    "# help(model.fit) # DMatrix 설명 없고, enable_category 에 대한 언급도 없다\n",
    "# When categorical type is supplied, DMatrix parameter `enable_categorical` must be set to `True`. \n",
    "# Invalid columns:vs, am_manual, wt_class\n",
    "y_train_predict= model.predict(xgboost_X_train)\n",
    "y_test_predict= model.predict(xgboost_X_test)\n",
    "# 70% 모델 평가, 나머지 30% 로 모델 평가[R2, MAE, MSE]\n",
    "print('train R2: ',r2_score(xgboost_y_train, y_train_predict))\n",
    "print('test R2: ',r2_score(xgboost_y_test, y_test_predict))\n",
    "print('test MAE: ',mean_absolute_error(xgboost_y_test, y_test_predict))\n",
    "print('test MSE: ',mean_squared_error(xgboost_y_test, y_test_predict))\n",
    "print(f\"XGB Regressor 수행시간: {time.time()-start_time:.7} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd77cb",
   "metadata": {},
   "source": [
    "### Regressor 결론\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab7dd84",
   "metadata": {},
   "source": [
    "##### Linear Regression\n",
    "- R^2 test:  0.2905203422802105\n",
    "- 차이 > 0에 가까울수록 좋다\n",
    "- MAE test:  2.209756946563721\n",
    "- MSE test:  7.047970919788388\n",
    "- RMSE test:  2.6548014840639946\n",
    "\n",
    "##### Random Forest\n",
    "- R2 train:  0.9809794570146911\n",
    "- R2 test:  0.45810313267565417\n",
    "- MAE test:  1.7127200000000264\n",
    "- MSE test:  5.383203480000051\n",
    "- RMSE test:  2.3201731573311615\n",
    "- 랜포 실행시간 1.788558 sec\n",
    "\n",
    "##### Gradient Boosting\n",
    "- R2 train r2_:  0.9999940057279647\n",
    "- R2 test:  0.2191733401187025\n",
    "- MAE test:  2.007699537572006\n",
    "- MSE test:  7.756732039260808\n",
    "- 그래디언트부스팅 수행시간: 0.08700275 sec\n",
    "\n",
    "##### XG Boosting\n",
    "- train R2:  0.9999999861571242\n",
    "- test R2:  0.2905203422802105\n",
    "- test MAE:  2.209756946563721\n",
    "- test MSE:  7.047970919788388\n",
    "- XGB Regressor 수행시간: 0.1259995 sec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
